{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "k2gbDgLutnbz",
    "outputId": "b4453830-177e-411a-86e8-96ad6cc52f9a",
    "ExecuteTime": {
     "end_time": "2023-06-07T06:38:57.960990Z",
     "start_time": "2023-06-07T06:38:54.332987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv('Data/train.csv') # Loads in the training data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Introduction**\n",
    "I started constructing this notebook after stumbling upon a video made by Samson Zhang. He explained how learning the foundational concepts of a neural network without the assistance of popular libraries/frameworks such as TensorFlow, PyTorch, and Keras enabled him to gain a more thorough understanding of machine learning. As I tried to understand what was happening in their notebook, I spent hours trying to connect all the dots between dozens of sources and figure out *why* this model worked and *how* we got the calculations. That's when I decided to organize everything into one, comprehensive notebook that is understandable to most people with a surface-level understanding of calculus, linear algebra, and python.\n",
    "\n",
    "This notebook was inspired by and modeled after one created by Samson Zhang, found [here](https://www.kaggle.com/code/wwsalmon/simple-mnist-nn-from-scratch-numpy-no-tf-keras/notebook). I have added additional features and made some modifications to improve performance. Notably, I have **significantly** expanded on and edited the accompanying text to increase clarity.\n",
    "\n",
    "Additionally, I have implemented object-oriented programming (OOP) to improve modularity. **This guide will assume the use of 3 total layers with the hidden layer using ReLU as its activation function.** Knowing what those mean isn't important right now (we'll cover them later). **It will also use indexing throughout to represent these layers ([0], [1], [2])**. It's important that you remember that altering the number of layers and the activation functions may affect the logic of this guide.\n",
    "\n",
    "The MNIST dataset is from Kaggle, found [here](https://www.kaggle.com/c/digit-recognizer).\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Resource Recommendations**\n",
    "Here are some of the resources I have found the most helpful. Some have unique styles, or are a part of a larger series, so find the one that most suits you!\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "### **Machine Learning/Neural Networks**\n",
    "[\"Why Neural Networks can learn (almost) anything\"](https://www.youtube.com/watch?v=0QczhVg5HaI) - Emergent Garden\n",
    "\n",
    "[Neural Networks (Series)](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) - 3Blue1Brown\n",
    "\n",
    "[Neural Networks/Deep Learning (Series)](https://www.youtube.com/playlist?list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1) - StatQuest with Josh Starmer\n",
    "\n",
    "[Machine Learning (Series)](https://www.youtube.com/playlist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF) - StatQuest with Josh Starmer\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### **Mathematics**\n",
    "[Essence of Linear Algebra (Series)](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) - 3Blue1Brown\n",
    "\n",
    "[Essence of Calculus (Series)](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) - 3Blue1Brown\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Definitions**\n",
    "These are some definitions that are either helpful to have as a reference or not covered in this notebook.\n",
    "\n",
    "*All terms are described in the context of machine learning and neural networks. In other applications, these definitions may differ.*\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Arrays**\n",
    "The dimensionality of an array in the context of data structures can be different from the dimensionality of the space it's used to represent. For example, a \"2-D vector\" is a 1-D collection of 2 values that represents a point or direction in two-dimensional space. Additionally, a \"1-D Matrix\" is considered a vector. The dimensionality of the data structures never changes, but the dimensionality of its contents can.\n",
    "\n",
    "**Scalar**\n",
    "0-Dimensional single, real or complex number.\n",
    "\n",
    "**Vector**\n",
    "1-Dimensional array of numbers that can be represented as either a row or a column.\n",
    "\n",
    "**Matrix**\n",
    "2-Dimensional array of numbers where each row or column represents an array.\n",
    "\n",
    "**Tensor**\n",
    "N-Dimensional array of numbers, known as \"N-Order\" tensor. Scalars (0-D tensors), vectors (1-D tensors), and matrices (2-D tensors) are specific types of tensors.\n",
    "\n",
    "<br>\n",
    "<img src=\"Images/Arrays.jpeg\" alt=\"Arrays\" width=\"1200\">\n",
    "\n",
    "Image source: Jovian.com\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Components**\n",
    "**Training Set**\n",
    "Usually the largest set in a given dataset that is used to train the model and adjust parameters.\n",
    "\n",
    "**Validation Set**\n",
    "Also known as the \"dev set\", this is a subset of the training set that is used to evaluate performance and tune hyperparameters.\n",
    "\n",
    "**Testing Set**\n",
    "A set used to assess the final performance and generalization capability of a model. It is kept separate from the training and validation sets and unseen to the model to ensure uninfluenced decisions.\n",
    "\n",
    "**Node/Neuron**\n",
    "The fundamental of a neural network that takes inputs, applies weights and biases, performs computations, and produces outputs.\n",
    "\n",
    "**Regularization Strength**\n",
    "A value used to prevent overfitting that adds a penalty to the loss function to encourage simpler representations. If it's set too high, it could lead to underfitting and poor results. If it's set too low, it could lead to overfitting and poor results.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Miscellaneous**\n",
    "**Overfitting**\n",
    "A scenario that occurs when a model is overly complex, which leads to the model learning randomness and not underlying patterns. It will have good performance on training data at the expense of good performance on the testing data.\n",
    "\n",
    "**Underfitting**\n",
    "A scenario that occurs when a model is not complex enough, which leads to the model developing little capacity to capture patterns. It will have poor performance on both the training and testing sets.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Overview**\n",
    "The data we'll be working with is the MNIST dataset. It consists of tens of thousands handwritten images of digits. Thankfully, we don't have to worry about image processing because the images have been converted into values inside a .csv file. Each \"image\" now consists of a 28x28 grid of values (784 total), which has been transformed into a one-dimensional array. Each value is on a scale from 0 to 255, with 0 being completely black and 255 being completely white. By dividing these values by 255, we can normalize them to be on a scale from 0 to 1.\n",
    "\n",
    "<br>\n",
    "<img src=\"Images/Digits_Example.jpeg\" alt=\"Digits Example\" width=\"1200\">\n",
    "\n",
    "Image source: medium.com\n",
    "<br>\n",
    "\n",
    "The dataset is split into two files: the training data and the testing data. The training data is much larger than the testing data because our model will need a lot of information to try to correctly identify the handwritten digits in the testing data. These two datasets are completely disconnected from each other. The testing data will only be introduced to the model after we are completely done with training. From there, the model no longer updates its parameters, and it remains the same throughout the testing data.\n",
    "\n",
    "There is one important distinction between the training and testing data, however. Each image in the training data is accompanied by a label that represents what digit that image represents. Therefore, each array of image data in the training data is actually 785 values (we'll separate the labels from each vector later). Now, we have tens of thousands arrays of length 785 to run through our model!\n",
    "\n",
    "This network will have three total layers: an input layer, a hidden layer, and an output layer.\n",
    "\n",
    "<br>\n",
    "<img src=\"Images/Network_Layers.jpeg\" alt=\"Network Layers\" width=\"1200\">\n",
    "\n",
    "Image source: medium.com\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Data Handling**\n",
    "Since each image is represented by a vector with 784 values, and we have tens of thousands of images, performing operations on these images would require a large amount of computational power. Thankfully, we can take advantage of vectorized calculations by stacking the vectors together into one matrix to increase efficiency. Vectorized calculations involve performing operations on entire arrays rather than individual elements, which significantly speeds up computation time. Some examples of vectorized calculations we'll implement are dot products, matrix multiplication, and element-wise operations.\n",
    "\n",
    "In most applications, these vectors would be represented as rows of the matrix with dimensions $m \\times n$ where $m$ is the number of training examples and $n$ is the number of input features (784). In linear algebra, $m$ refers to the number of rows and $n$ refers to the number of columns. Another alteration we're going to make to our data is transposing it. This is common practice in machine learning because it allows our data to adhere to the conventions of linear algebra and also specific algorithms. Now, our matrix will have dimensions $n \\times m$, with each column corresponding to a training example and each row a training feature. A transposed matrix is denoted by the addition of a superscripted $T$.\n",
    "\n",
    "<br>\n",
    "<img src=\"Images/Transpose.jpeg\" alt=\"Transpose\" width=\"1200\">\n",
    "\n",
    "Image source: cuemath.com\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Input Layer**\n",
    "The input layer is the very first layer of our neural network. Essentially, this layer's only purpose is to represent the input data, or input features. This layer is often disregarded when counting how many layers a network has, so ours would only be a two-layer neural network.\n",
    "\n",
    "Throughout the entire process of training our model, this layer will always have 784 nodes, or neurons. You can think of these as a unit of the neural network that holds and processes data. Individually, nodes don't do much. When you connect them to other nodes and apply functions to them, however, that's how we make a neural network.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Hidden Layer**\n",
    "\n",
    "The hidden layer is the first layer of our network that performs some action on the data. The number of nodes in any hidden layer is arbitrary, it's entirely up to you how many you want to incorporate. You can increase or decrease the amount as much as you like depending on the performance of the model. In fact, most neural networks have multiple hidden layers, but we're using one to keep things simple.\n",
    "\n",
    "Since no values are associated with the nodes in the hidden layer, now we have to perform some operation on the data. We're now going to introduce weights and biases to our model, each of which starts off as completely randomized values. These two parameters are the primary parameters that are updated during the training process.\n",
    "\n",
    "We're also going to apply an activation function to the values associated with the hidden layer. The choice of activation function is another element of a neural network that can be altered. For this, we're going to use what's called a rectified linear unit (ReLU) activation function. ReLU will take in \"weighted sums\", \"pre-activation values\", \"logits\" and perform an operation on each of those to return \"activations\", or \"activation values\".\n",
    "\n",
    "After ReLU has been used, these values are ready to move onto the next layer.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Output Layer**\n",
    "\n",
    "Our output layer will have 10 nodes, one for each possible digit. We will introduce another set of weights and biases connecting the hidden layer to the output layer. Once again, we will apply an activation function to the pre-activation values specific to this layer. However, the output layer is going to use a different one than ReLU called a softmax function.\n",
    "\n",
    "A softmax function will transform our pre-activation values into an array of probabilities that sums up very nicely to 1. Essentially, each probability value of the output layer represents how confident the model is that a certain image is a particular digit. Now, we have our final output.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "id": "TQTOzEwgtnb1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "np.random.shuffle(data) # Shuffles the data to prevent overfitting\n",
    "\n",
    "class PreprocessData:\n",
    "    \"\"\"\n",
    "    This class is used to preprocess the data and split it into training and validation sets.\n",
    "\n",
    "    Attributes:\n",
    "        data (np.array): The data to be preprocessed.\n",
    "        m (int): The number of training examples.\n",
    "        n (int): The number of features.\n",
    "        X (np.array): The input features (data directly from the images).\n",
    "        Y (np.array): The true labels (correct \"answers\").\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.m, self.n = self.data.shape # Assigns the dimensions of the data to m and n\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "\n",
    "    @property\n",
    "    def input_size(self):\n",
    "        if self.X is not None:\n",
    "            return self.X.shape[0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def normalize(self):\n",
    "        self.X = self.X / 255.0\n",
    "\n",
    "class Validate(PreprocessData):\n",
    "    \"\"\"\n",
    "    This subclass is used to preprocess the validation data.\n",
    "    \"\"\"\n",
    "    validate_data = None\n",
    "\n",
    "    def __init__(self, data, dataset_size=1000):\n",
    "        super().__init__(data)\n",
    "        self.size = dataset_size\n",
    "        self.data = self.data[0:self.size].T\n",
    "        self.m, self.n = self.data.shape\n",
    "        self.Y = self.data[0]\n",
    "        self.X = self.data[1:, :]\n",
    "        self.normalize()\n",
    "        Validate.validate_data = self\n",
    "\n",
    "class Train(PreprocessData):\n",
    "    \"\"\"\n",
    "    This subclass is used to preprocess the training data.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "        self.size = Validate.validate_data.size\n",
    "        self.data = self.data[self.size:self.m].T\n",
    "        self.Y = self.data[0]\n",
    "        self.X = self.data[1:, :]\n",
    "        self.normalize()\n",
    "        _, self.m = self.X.shape\n",
    "\n",
    "validate_data = Validate(data, dataset_size=1000)\n",
    "train_data = Train(data)"
   ],
   "metadata": {
    "id": "AiOGvYJftnb3",
    "ExecuteTime": {
     "end_time": "2023-06-07T06:38:59.782124Z",
     "start_time": "2023-06-07T06:38:57.967761Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Transposing**\n",
    "It may be quite confusing to visualize why we transposed matrices and how transposing actually works. In order to clear some potential confusion, we'll work through an example very similar to the operations that were just performed in the above code. Note, $y_i$ will be used to represent the true labels of our training data (the ones we separated from the rest). This notation will be expanded on in the future, but I thought it would help increase clarity.\n",
    "\n",
    "This is a matrix $A$ representing the training data, with 5 rows and 3 columns:\n",
    "$$A = \\begin{bmatrix}\n",
    "{y}_0 & 1 & 2 \\\\\n",
    "{y}_1 & 3 & 4 \\\\\n",
    "{y}_2 & 5 & 6 \\\\\n",
    "{y}_3 & 7 & 8 \\\\\n",
    "{y}_4 & 9 & 10\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "For our validation data $B$, extract the first 2 rows and transpose the result as $B^{T}$. We'll use validation_data = data[0:2].T:\n",
    "\n",
    "$$B = \\begin{bmatrix}\n",
    "{y}_0 & 1 & 2 \\\\\n",
    "{y}_1 & 3 & 4\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$B^{T} = \\begin{bmatrix}\n",
    "{y}_0 & {y}_1 \\\\\n",
    "1 & 3 \\\\\n",
    "2 & 4\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Next, retrieve the true label vector $B_{Y}$ and then the input features matrix $B_{X}$. We'll use Y_validation = validation_data[0] and X_validation = validation_data[1:3]:\n",
    "\n",
    "$$B^{T}_{Y} = \\begin{bmatrix}\n",
    "{y}_0 & {y}_1 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "$$B^{T}_{X} = \\begin{bmatrix}\n",
    "1 & 3 \\\\\n",
    "2 & 4\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "As you can see, we've separated the true labels from the data array. Now, we can use the true labels later on when we need to inform the model on whether it correctly predicted the digit.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Parameters**\n",
    "Recall, the layers of our neural network are 0-indexed where the current layer is represented by $k$. The weight matrices and bias vectors utilize this notation.\n",
    "\n",
    "As mentioned previously, weights and biases are the primary parameters that are adjusted by the model.\n",
    "\n",
    "Every node in the input layer has a weight value connecting to every node in the hidden layer (that's a lot of connections!). This is where the \"network\" part of neural network is emphasized.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Weight**\n",
    "Weights are learnable parameters that determine the strength of the connections between nodes in adjacent layers. Each weight value in the matrix influences the contribution, or importance, of the connection between a node in the previous layer $k-1$ to a node in the current layer $k$. These values are used to calculate the pre-activation values.\n",
    "\n",
    "$$W^{[k]} = \\begin{bmatrix}\n",
    "w_{0,0} & w_{0,1} & \\dots & w_{0,n} \\\\\n",
    "w_{1,0} & w_{1,1} & \\dots & w_{1,n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "w_{m,0} & w_{m,1} & \\dots & w_{m,n}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Each row of $W^{[k]}$ represents the connections between all nodes of the previous layer $k-1$ to a particular node in the current layer $k$, while each column of $W^{[k]}$ represents the connections between a particular node of the previous layer $k-1$ to all nodes in the current layer $k$.\n",
    "\n",
    "The weight $w_{m,n}$ represents the weight value for the connection from the $n-th$ node in the previous layer $k-1$ to the $m-th$ node in the current layer $k$. In the first weight matrix $W^{[1]}$, $m=10$ and $n=784$ which results in a matrix with 7,840 elements. In the second weight matrix $W^{[2]}$, $m=10$ and $n=10$ which results in a matrix with 100 elements. Note, $m$ and $n$ are serving two purposes in this context. In $W^{[k]}$, $m$ represents both the row index and the number of rows, while $n$ represents both the column index and the amount of columns. $W^{[k]}$ is of size $m \\times n$.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Bias**\n",
    "Biases are a set of learnable parameters that are added to thw pre-activation values, just before applying an activation function. Bias is used to shift the axis of an activation function to ensure certain input values (especially those will a value of 0, which can still be helpful information to guide the model) don't get cut off when calculating predictions. It also ensures that all variations of input values are captured. For example, the model will still identify a digit shifting to the left, even though it's in an entirely different position than it was previously.\n",
    "\n",
    "$$b^{[k]} = \\begin{bmatrix}\n",
    "b_0  \\\\\n",
    "b_1  \\\\\n",
    "\\vdots  \\\\\n",
    "b_n\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "The bias $b_n$ represents the bias value of the $n-th$ node in the current layer $k$.\n",
    "\n",
    "Both bias vectors in our neural network, $b^{[1]}$ and $b^{[2]}$, contain 10 elements, one for each node in their respective layers.\n",
    "\n",
    "<br>\n",
    "<img src=\"Images/Bias_ReLU.jpeg\" alt=\"Bias and ReLU\" width=\"1200\">\n",
    "\n",
    "Image source: turing.com\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Layer Operations**\n",
    "This is where we actually start getting into what calculations happen in our network! It's relatively simple, but there are a lot of moving parts, so ensure you understand each before moving on.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Pre-Activation Values**\n",
    "Pre-activation values, also called weighted sums, are calculated by computing the dot product of a weight matrix $W^{[k]}$ and input values $X$ or $A^{[1]}$, depending on which layer the pre-activation values are calculated, plus a bias value $b^{[k]}$. In our network, each set of pre-activation values results in a vector with 10 elements, equal to the number of nodes in each layer.\n",
    "\n",
    "<br>\n",
    "<img src=\"Images/Dot_Product.jpeg\" alt=\"Dot Product\" width=\"1200\">\n",
    "\n",
    "Image source: algebra1course.wordpress.com\n",
    "<br>\n",
    "\n",
    "*Note, the term \"input values\" generally refers to values that are used as an input to a function (in this case, our pre-activation values calculation). It's different from the term \"input features\", which exclusively refers to the values in the input layer that represent the image data from our dataset.*\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Activation Values**\n",
    "As the name might suggest, these are the values obtained after applying an activation function, and the final operation performed in their respective layer. Before we demonstrate how this is done, we need to provide the activation functions we'll be using in this neural network.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### **ReLU**\n",
    "Rectified Linear Unit (ReLU) is an activation function that returns the input value $x$ if $x>0$, and zero otherwise. ReLU introduces non-linearity to the network, allowing it to learn and represent complex relationships between inputs and outputs.\n",
    "\n",
    "ReLU function:\n",
    "$$f(x) = max(0, x)$$\n",
    "\n",
    "<br>\n",
    "<img src=\"Images/ReLU.jpeg\" alt=\"ReLU\" width=\"1200\">\n",
    "\n",
    "Image source: vidyasheela.com\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### **Softmax**\n",
    "The softmax function transforms a vector $Z$ into a probability distribution. Each element in the output vector represents the probability of the input belonging to a particular class. The output vector is one whose elements sum up to 1 and are all non-negative (these are really important properties).\n",
    "\n",
    "Softmax function:\n",
    "$$\\hat{y}_i = \\frac{e^{Z_i}}{\\sum_{j=0}^{C-1} {e^{Z_j}}}$$\n",
    "\n",
    "In this, ${Z_i}$ represents the input vector of pre-activation values, ${e^{Z_i}}$ represents a particular node, $e^{Z_j}$ represents all nodes and $C$ represents the number of classes. The numerator raises $e$ to the power of some value $Z_i$ of the input vector. The denominator raises $e$ to the power of each $Z_j$, which is $C$ classes, and then sums up all these terms.\n",
    "\n",
    "<br>\n",
    "<img src=\"Images/Softmax.jpeg\" alt=\"Softmax\" width=\"1200\">\n",
    "\n",
    "Image source: vitalflux.com\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Forward Propagation**\n",
    "As the name suggests, our neural network will do two separate passes: a forwards pass (forward propagation) and a backwards pass (backpropagation). This section will explain what happens during forward propagation.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Hidden Layer**\n",
    "The first operation in this layer is to calculate the pre-activation values by inserting our randomized weight and bias arrays, $W^{[1]}$ and $b^{[1]}$, into the following function:\n",
    "$$Z^{[1]} = W^{[1]} \\cdot X + b^{[1]}$$\n",
    "\n",
    "In this, $Z^{[1]}$ represents our pre-activation values and $X$ represents our input features. $Z^{[1]}$ is a new matrix of dimensions $10\\times m$, where $m$ represents the number of training examples. The entire matrix represents carrying out the first step of forward propagation for all training examples at the same time (this approach was intentionally chosen, it will be expanded on in the \"gradient descent\" section).\n",
    "\n",
    "Next, we need to apply an activation function to $Z^{[1]}$. In this model, our chosen activation function for this layer is ReLU. From $Z^{[1]}$, we'll calculate $A^{[1]}$, which represents the values of our nodes in the hidden layer after applying the activation function:\n",
    "$$A^{[1]} = \\text{ReLU}(Z^{[1]})$$\n",
    "\n",
    "Now, we can proceed to calculate the values of the output layer.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Output Layer**\n",
    "The same methodology as the hidden layer applies here. We take in input values from a previous layer, calculate the pre-activation values, and then calculate our activation values.\n",
    "\n",
    "First, we'll calculate $Z^{[2]}$:\n",
    "$$Z^{[2]} = W^{[2]} \\cdot A^{[1]} + b^{[2]}$$\n",
    "\n",
    "Then, we'll apply an activation function to $Z^{[2]}$. For the output layer, we've chosen the softmax activation function:\n",
    "$$A^{[2]} = \\text{softmax}(Z^{[2]})$$\n",
    "\n",
    "That's forward propagation! We went from input features, to hidden layer activation values, and then to output layer activation values.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Backpropagation**\n",
    "Backpropagation, or \"backprop\" is the derivative of the loss function with respect to the softmax output. The \"loss\" (calculated by finding the difference between the model's predictions and the true labels) is also commonly referred to as the \"cost\". Our objective for backprop is to minimize the cost of our neural network by manipulating the weights and biases. When the cost is lower, our model is more accurate.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "## One-Hot Encoding\n",
    "One-hot encoding is a method that converts discrete variables into numeric data. In our neural network, this is used on the labels for each image (0-9), which is a discrete variable. Using one-hot encoding, these labels are converted into a binary vector of length 10 (one for each digit). Each position in the vector corresponds to a digit, and the position representing the correct digit is marked with a 1, while all other positions are marked with a 0.\n",
    "\n",
    "We'll show an example of this in the next section.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Loss Function**\n",
    "A common choice for the loss function given the implementation of softmax is called \"cross-entropy loss\" because of the two properties of a softmax output vector mentioned earlier. Furthermore, since we're dealing with a multi-class classification problem (digits 0-9), cross-entropy loss is a great choice.\n",
    "\n",
    "Cross-entropy loss function:\n",
    "$$L_{CE} = -\\sum_{i=0}^{C-1} y_i \\cdot \\log(\\hat{y}_i)$$\n",
    "\n",
    "Note, in the context of machine learning, natural log is typically used when referring to \"log\", which derives nicely to $\\frac{1}{x}$. Try not to confuse the log used in cross-entropy for the log traditionally used in other applications.\n",
    "\n",
    "In this, ${y}_i$ is the true label (0 or 1) from one-hot encoding, ${\\hat{y}_i}$ is the probability confidence from softmax. Just as in softmax, $C$ represents the number of classes.\n",
    "\n",
    "For example, $\\hat{y}$ could look like:\n",
    "$$\\begin{bmatrix} 0.02, \\ 0.00, \\ 0.03, \\ 0.05, \\ 0.01, \\ 0.06, \\ \\textbf{0.72}, \\ 0.09, \\ 0.00, \\ 0.02 \\end{bmatrix}$$\n",
    "\n",
    "If the true label for this example was 6, $y$ would look like:\n",
    "$$\\begin{bmatrix} 0, \\ 0, \\ 0, \\ 0, \\ 0, \\ 0, \\ \\textbf{1}, \\ 0, \\ 0, \\ 0 \\end{bmatrix}$$\n",
    "\n",
    "As you can see, $y_i = 0$ for all $i$ except the correct label. Consequently, the only $\\hat{y}$ value that influences the cost is the correct label.\n",
    "\n",
    "To visualize this, the loss function of our example would look like:\n",
    "$$L_{CE} = - (y_0 \\cdot \\log(\\hat{y}_0)) + \\dots + (y_6 \\cdot \\log(\\hat{y}_6)) + \\dots + (y_9 \\cdot \\log(\\hat{y}_9))$$\n",
    "$$= - (0 \\cdot \\log(0.02) + \\dots + (1 \\cdot \\log(0.72)) + \\dots + (0 \\cdot \\log(0.02))$$\n",
    "$$= -\\log(0.72) \\approx \\textbf{0.143}$$\n",
    "\n",
    "Since the objective is to minimize the cost (get closer to 0), the model would have demonstrated better performance if ${\\hat{y}_6}$ were larger:\n",
    "$$L_{CE} = -\\log(\\hat{y}_6) = -\\log(0.86) \\approx \\textbf{0.060}$$\n",
    "\n",
    "The closer ${\\hat{y}}$ is to 1, the closer the cost is to 0.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    A class used to represent a layer in a neural network.\n",
    "\n",
    "    Attributes:\n",
    "        nodes (int): The number of nodes in the layer.\n",
    "        activation (str): The activation function to use for the layer.\n",
    "        W (np.array): The weight matrix for the layer.\n",
    "        b (np.array): The bias vector for the layer.\n",
    "        Z (np.array): The pre-activation values for the layer.\n",
    "        A (np.array): The activation values for the layer.\n",
    "        dW (np.array): The gradient of the cost function with respect to W.\n",
    "        db (np.array): The gradient of the cost function with respect to b.\n",
    "        dZ (np.array): The gradient of the cost function with respect to Z.\n",
    "    \"\"\"\n",
    "    def __init__(self, nodes, activation='input'):\n",
    "        self.nodes = nodes\n",
    "        self.activation = activation\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.Z = None\n",
    "        self.A = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        self.dZ = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        Returns the string representation of the layer.\n",
    "        \"\"\"\n",
    "        return f'Layer(nodes={self.nodes}, activation={self.activation})'\n",
    "\n",
    "    def randomize_parameters(self, prev_nodes):\n",
    "        \"\"\"\n",
    "        Randomly initializes the weight matrix and bias vector for the layer.\n",
    "\n",
    "        Args:\n",
    "            prev_nodes (int): The number of nodes in the previous layer.\n",
    "        \"\"\"\n",
    "        self.W = np.random.rand(self.nodes, prev_nodes) - 0.5\n",
    "        self.b = np.random.rand(self.nodes, 1) - 0.5\n",
    "\n",
    "    def update_one_hot_Y(self, one_hot_Y):\n",
    "        \"\"\"\n",
    "        Updates the one_hot_Y attributes of the layer.\n",
    "        \"\"\"\n",
    "        self.one_hot_Y = one_hot_Y\n",
    "\n",
    "    def forward_propagation(self, prev_layer_input):\n",
    "        \"\"\"\n",
    "        Calculates the pre-activation and activation values for the layer.\n",
    "\n",
    "        Args:\n",
    "            prev_layer_input (np.array): The input values from the previous layer.\n",
    "        \"\"\"\n",
    "        self.Z = self.W.dot(prev_layer_input) + self.b\n",
    "        self.A = ActivationFunction.function(self.activation, self.Z)\n",
    "\n",
    "    def backpropagation(self, prev_layer, next_layer, is_first_layer=False):\n",
    "        \"\"\"\n",
    "        Calculates the gradients of the cost function with respect to W, b, and Z.\n",
    "\n",
    "        Args:\n",
    "            prev_layer (Layer): The previous layer.\n",
    "            next_layer (Layer): The next layer.\n",
    "            is_first_layer (bool): Whether the layer is the first hidden layer.\n",
    "        \"\"\"\n",
    "        m = self.A.shape[1]\n",
    "\n",
    "        if next_layer is None: # Indicates the output layer\n",
    "            self.dZ = self.A - self.one_hot_Y\n",
    "        else:\n",
    "            self.dZ = next_layer.W.T.dot(next_layer.dZ) * ActivationFunction.derivative(self.activation, self.Z)\n",
    "\n",
    "        if is_first_layer:\n",
    "            self.dW = self.dZ.dot(prev_layer.T) / m\n",
    "        else:\n",
    "            self.dW = self.dZ.dot(prev_layer.A.T) / m\n",
    "\n",
    "        self.db = np.sum(self.dZ, axis=1, keepdims=True) / m"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T06:38:59.792164Z",
     "start_time": "2023-06-07T06:38:59.790539Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "    \"\"\"\n",
    "    A class used to represent and calculate an activation function and its derivative.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def function(name, Z):\n",
    "        if name == 'input':\n",
    "            return Z\n",
    "        elif name == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-Z))\n",
    "        elif name == 'tanh':\n",
    "            return np.tanh(Z)\n",
    "        elif name == 'relu':\n",
    "            return np.maximum(Z, 0)\n",
    "        elif name == 'softmax':\n",
    "            return np.exp(Z) / np.sum(np.exp(Z), axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def derivative(name, Z):\n",
    "        if name == 'sigmoid':\n",
    "            s = 1 / (1 + np.exp(-Z))\n",
    "            return s * (1 - s)\n",
    "        elif name == 'tanh':\n",
    "            return 1 - np.tanh(Z)**2\n",
    "        elif name == 'relu':\n",
    "            return (Z > 0).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T06:38:59.811955Z",
     "start_time": "2023-06-07T06:38:59.799877Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Gradient Descent**\n",
    "\n",
    "To optimize our neural network (minimize the cost) and improve the accuracy of our model, we will now calculate gradient descent, which is an optimization algorithm that finds the parameters that minimize the loss function. It adjusts towards the direction of the steepest descent in the loss function gradient. It utilizes the chain rule to compute the gradient of the loss function with respect to each parameter.\n",
    "\n",
    "There are various implementations of gradient descent, but we are implementing what's called \"batch gradient descent\" because it's pretty straightforward. This implementation calculates the average gradient of the loss function over all training examples before updating the parameters (i.e., all images are run forwards and backwards at the same time). It results in accurate, but computationally expensive calculations.\n",
    "\n",
    "The algorithm updates our parameters by subtracting the derivative of the loss function with respect to a particular parameter, from that same parameter. Following this, the formulas are:\n",
    "$$W^{[1]} = W^{[1]} - \\alpha \\cdot \\frac{\\delta L_{CE}}{\\delta W^{[1]}}$$\n",
    "$$b^{[1]} = b^{[1]} - \\alpha \\cdot \\frac{\\delta L_{CE}}{\\delta b^{[1]}}$$\n",
    "$$W^{[2]} = W^{[2]} - \\alpha \\cdot \\frac{\\delta L_{CE}}{\\delta W^{[2]}}$$\n",
    "$$b^{[2]} = b^{[2]} - \\alpha \\cdot \\frac{\\delta L_{CE}}{\\delta b^{[2]}}$$\n",
    "\n",
    "Here, $\\alpha$ is the learning rate. It's a hyperparameter that is explicitly set by the user rather than one that gradient descent optimizes. The learning rate value controls the step size of gradient descent. If it's set too high, it could lead to overshooting and instability. If it's set too low, it could lead to a slow model.\n",
    "\n",
    "<br>\n",
    "<img src=\"Images/Gradient_Descent.jpeg\" alt=\"Gradient Descent\" width=\"1200\">\n",
    "\n",
    "Image source: analyticsvidhya.com\n",
    "<br>\n",
    "\n",
    "To perform gradient descent and update our parameters using the functions listed above, we need to find these first:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta W^{[1]}} \\text{, or } dW^{[1]}$$\n",
    "$$\\frac{\\delta L}{\\delta b^{[1]}} \\text{, or } db^{[1]}$$\n",
    "$$\\frac{\\delta L_{CE}}{\\delta W^{[2]}} \\text{, or } dW^{[2]}$$\n",
    "$$\\frac{\\delta L_{CE}}{\\delta b^{[2]}} \\text{, or } db^{[2]}$$\n",
    "\n",
    "Since we're going backwards, we'll calculate $dW^{[2]}$ and $db^{[2]}$ first. To do this, we need to find the derivative of the loss function (${\\delta L_{CE}}$) with respect to the inputs of the output layer $(\\delta Z_i)$. We'll show how this was calculated later, but it is defined as:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta {Z_i}} = {\\hat{y}_i} -{y_i}$$\n",
    "\n",
    "This line represents this expression our in backpropagation function:\n",
    "$${{dZ^{[2]}} = {A^{[2]} - Y}}$$\n",
    "\n",
    "Just as defined earlier, ${\\hat{y}_i}$, or $Y$ represents the one-hot encoded labels, and ${y_i}$, or ${A^{[2]}}$ represents the output of the final layer after softmax.\n",
    "\n",
    "Once we have ${dZ^{[2]}}$, we can calculate ${dW^{[2]}}$ and ${db^{[2]}}$:\n",
    "$$dW^{[2]} = \\frac{dZ^{[2]} A^{[1]T}}{m}$$\n",
    "$$dB^{[2]} = \\frac{\\Sigma {dZ^{[2]}}}{m}$$\n",
    "\n",
    "Here, $dW^{[2]}$ and $db^{[2]}$ are divided by m to normalize them.\n",
    "\n",
    "Then, to continue moving backwards through the network, we need to calculate $dW^{[1]}$ and $db^{[1]}$. Similar to calculating ${dW^{[2]}}$ and ${db^{[2]}}$, we'll first calculate:\n",
    "$$dZ^{[1]} = W^{[2]T} dZ^{[2]} \\cdot g^{[1]\\prime} (Z^{[1]})$$\n",
    "\n",
    "On the right side of the expression, $g^{[1]\\prime}(Z^{[1]})$ is the derivative of the activation function $g$ (which is ReLU because this is working on the hidden layer where ReLU was used) with respect to $Z$.\n",
    "\n",
    "Recall the ReLU function:\n",
    "$$f(x) = max(0, x)$$\n",
    "\n",
    "The derivative of ReLU (covered earlier) is 1 if x > 0, and 0 if x <= 0.\n",
    "\n",
    "To find $dW^{[1]}$ and $db^{[1]}$, it's similar to finding ${dW^{[2]}}$ and ${db^{[2]}}$. However, instead of $A^{[1]}$, we'll use $X$ which represents the input features:\n",
    "$$dW^{[1]} = \\frac{dZ^{[1]} X^T}{m}$$\n",
    "$$db^{[1]} = \\frac{\\Sigma {dZ^{[1]}}}{m}$$\n",
    "\n",
    "Next, we need to update our weight and bias parameters using the expressions defined in the beginning of this section:\n",
    "$$W^{[1]} = W^{[1]} - \\alpha \\cdot dW^{[1]}$$\n",
    "$$b^{[1]} = b^{[1]} - \\alpha \\cdot db^{[1]}$$\n",
    "$$W^{[2]} = W^{[2]} - \\alpha \\cdot dW^{[2]}$$\n",
    "$$b^{[2]} = b^{[2]} - \\alpha \\cdot db^{[2]}$$\n",
    "\n",
    "That's everything we'll need to carry out gradient descent and train the neural network! This will happen repeatedly until it reaches the desired performance.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \"\"\"\n",
    "    A class used to represent the neural network.\n",
    "\n",
    "    Attributes:\n",
    "        X (np.array): The input features.\n",
    "        Y (np.array): The true labels.\n",
    "        one_hot_Y (np.array): The one-hot encoded true labels.\n",
    "        layers (dict): The layers of the neural network.\n",
    "        layer_names (list): The names of the layers.\n",
    "        layer_objs (list): The layer objects.\n",
    "        layer_ct (int): The number of layers.\n",
    "        input_layer (Layer): The input layer.\n",
    "        hidden_layers (list): The hidden layers.\n",
    "        output_layer (Layer): The output layer.\n",
    "        cost_list (list): The cost values for each iteration.\n",
    "        accuracy_list (list): The accuracy values for each iteration.\n",
    "        iteration_list (list): The iteration values for each iteration.\n",
    "        visualizer (Visualizer): The visualizer for the neural network.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, Y, layers):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.one_hot_Y = self.one_hot_encode()\n",
    "        self.layers = layers\n",
    "        self.layer_names = []\n",
    "        self.layer_objs = []\n",
    "        self.layer_ct = None\n",
    "        self.input_layer = None\n",
    "        self.hidden_layers = None\n",
    "        self.output_layer = None\n",
    "\n",
    "        self.get_layers()\n",
    "        self.initialize_parameters()\n",
    "\n",
    "        self.cost_list = []\n",
    "        self.accuracy_list = []\n",
    "        self.iteration_list = []\n",
    "        self.visualizer = Visualizer(self)\n",
    "\n",
    "    def get_layers(self):\n",
    "        \"\"\"\n",
    "        Converts the layer dictionary into a list of layer objects and names. Sets the input, hidden, and output layers and error checks to ensure the layers are valid.\n",
    "        \"\"\"\n",
    "        input_activation_count = 0\n",
    "        softmax_activation_count = 0\n",
    "\n",
    "        for name, layer in self.layers.items():\n",
    "            self.layer_names.append(name)\n",
    "            self.layer_objs.append(layer)\n",
    "\n",
    "            if layer.activation == 'input':\n",
    "                input_activation_count += 1\n",
    "            elif layer.activation == 'softmax':\n",
    "                softmax_activation_count += 1\n",
    "\n",
    "            if layer.activation not in ['input', 'sigmoid', 'tanh', 'relu', 'softmax']:\n",
    "                raise Exception('Invalid activation function for ' + name + '. ' + 'Must use \\'sigmoid\\', \\'tanh\\', \\'relu\\', or \\'softmax\\'.')\n",
    "\n",
    "        self.layer_ct = len(self.layer_objs)\n",
    "        self.input_layer = self.layer_objs[0]\n",
    "        self.hidden_layers = self.layer_objs[1:-1]\n",
    "        self.output_layer = self.layer_objs[-1]\n",
    "\n",
    "        if self.layer_ct < 3:\n",
    "            raise Exception('Invalid number of layers. Must have at least 1 input layer, 1 hidden layer, and 1 output layer.')\n",
    "        elif input_activation_count > 1:\n",
    "            raise Exception('More than one layer has the \\'input\\' activation function.')\n",
    "        elif softmax_activation_count > 1:\n",
    "            raise Exception('More than one layer has the \\'softmax\\' activation function.')\n",
    "        elif self.input_layer.activation != 'input':\n",
    "            raise Exception('First layer must be an input layer. Can\\'t use ' + \"'\" + self.input_layer.activation + \"'\")\n",
    "        elif self.output_layer.activation != 'softmax':\n",
    "            raise Exception('Last layer must use softmax. Can\\'t use ' + \"'\" + self.input_layer.activation + \"'\")\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        Initializes the parameters for each layer.\n",
    "        \"\"\"\n",
    "        prev_nodes = 784\n",
    "        for index, layer in enumerate(self.layer_objs):\n",
    "            if layer == self.input_layer:\n",
    "                pass\n",
    "            elif layer in self.hidden_layers:\n",
    "                layer.randomize_parameters(prev_nodes)\n",
    "                prev_nodes = layer.nodes\n",
    "            elif layer == self.output_layer:\n",
    "                layer.randomize_parameters(prev_nodes)\n",
    "\n",
    "    def one_hot_encode(self):\n",
    "        \"\"\"\n",
    "        One-hot encodes the true labels.\n",
    "        \"\"\"\n",
    "        one_hot_Y = np.zeros((self.Y.size, self.Y.max() + 1))\n",
    "        one_hot_Y[np.arange(self.Y.size), self.Y] = 1\n",
    "        one_hot_Y = one_hot_Y.T\n",
    "        return one_hot_Y\n",
    "\n",
    "    @staticmethod\n",
    "    def print_progress(iteration, accuracy, cost):\n",
    "        \"\"\"\n",
    "        Prints the progress of the neural network during training.\n",
    "\n",
    "        Args:\n",
    "            iteration (int): The current iteration.\n",
    "            accuracy (float): The current accuracy.\n",
    "            cost (float): The current cost.\n",
    "        \"\"\"\n",
    "        print(f'Iteration: {iteration}')\n",
    "        print(f'Accuracy: {accuracy:.3f}%')\n",
    "        print(f'Cost: {cost:,.3f}\\n')\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_cost(output_activations, one_hot_Y, m):\n",
    "        \"\"\"\n",
    "        Calculates the cost of the neural network using cross-entropy loss.\n",
    "\n",
    "        Args:\n",
    "            output_activations (np.array): The output activations.\n",
    "            one_hot_Y (np.array): The one-hot encoded true labels.\n",
    "            m (int): The number of training examples.\n",
    "        \"\"\"\n",
    "        return -np.sum(one_hot_Y * np.log(output_activations)) / m\n",
    "\n",
    "    def forward_propagate(self, X):\n",
    "        \"\"\"\n",
    "        Performs forward propagation on the neural network.\n",
    "\n",
    "        Args:\n",
    "            X (np.array): The input features.\n",
    "        \"\"\"\n",
    "        self.input_layer.A = X\n",
    "        prev_layer = self.input_layer\n",
    "\n",
    "        for layer in self.layer_objs[1:]:\n",
    "            layer.forward_propagation(prev_layer.A)\n",
    "            prev_layer = layer\n",
    "\n",
    "    def backwards_propagate(self):\n",
    "        \"\"\"\n",
    "        Performs backwards propagation on the neural network.\n",
    "        \"\"\"\n",
    "        # Reversed list of layer objects, excluding the input layer\n",
    "        layer_objs_reversed = self.layer_objs[::-1][:-1]\n",
    "        next_layer = None\n",
    "\n",
    "        for index, current_layer in enumerate(layer_objs_reversed):\n",
    "            # Set prev_layer as input layer for the first hidden layer, or next layer in the list otherwise\n",
    "            prev_layer = self.X if current_layer == layer_objs_reversed[-1] else layer_objs_reversed[index + 1]\n",
    "\n",
    "            is_first_layer = current_layer == layer_objs_reversed[-1]\n",
    "            current_layer.backpropagation(prev_layer, next_layer, is_first_layer)\n",
    "            next_layer = current_layer\n",
    "\n",
    "    def update_params(self, alpha):\n",
    "        \"\"\"\n",
    "        Updates the parameters of the neural network as training progresses.\n",
    "\n",
    "        Args:\n",
    "            alpha (float): The learning rate.\n",
    "        \"\"\"\n",
    "        for layer in self.layer_objs:\n",
    "            if layer != self.input_layer:\n",
    "                layer.W -= alpha * layer.dW\n",
    "                layer.b -= alpha * layer.db\n",
    "\n",
    "    def optimizer(self, iterations, print_interval, graph_interval, alpha,):\n",
    "        \"\"\"\n",
    "        Optimizes the neural network using gradient descent, which aims to minimize the loss function by adjusting parameters.\n",
    "\n",
    "        Args:\n",
    "            iterations (int): The number of iterations to train for.\n",
    "            print_interval (int): The interval at which to print the progress of the neural network.\n",
    "            graph_interval (int): The interval at which to store the data that will be graphed.\n",
    "            alpha (float): The learning rate.\n",
    "        \"\"\"\n",
    "        m = self.Y.size\n",
    "        for layer in self.layer_objs:\n",
    "            layer.update_one_hot_Y(self.one_hot_Y)\n",
    "\n",
    "        for i in range(iterations):\n",
    "            self.forward_propagate(self.X)\n",
    "            self.backwards_propagate()\n",
    "            self.update_params(alpha)\n",
    "\n",
    "            if i % graph_interval == 0:\n",
    "                output_values = self.output_layer.A\n",
    "                cost = self.calculate_cost(output_values, self.one_hot_Y, m)\n",
    "                predictions = self.get_predictions(output_values)\n",
    "                accuracy_percent = self.get_accuracy(predictions, self.Y) * 100\n",
    "\n",
    "                self.cost_list.append(cost)\n",
    "                self.accuracy_list.append(accuracy_percent)\n",
    "                self.iteration_list.append(i)\n",
    "\n",
    "                if i % print_interval == 0:\n",
    "                    self.print_progress(i, accuracy_percent, cost)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_accuracy(predictions, Y):\n",
    "        \"\"\"\n",
    "        Calculates the accuracy of the predicted labels by comparing them to the true labels\n",
    "\n",
    "        Args:\n",
    "            predictions (np.array): The predictions of the neural network.\n",
    "            Y (np.array): The true labels.\n",
    "\n",
    "        Returns:\n",
    "            The accuracy of the neural network.\n",
    "        \"\"\"\n",
    "        return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "    @staticmethod\n",
    "    def get_predictions(output_values):\n",
    "        \"\"\"\n",
    "        Retrieves the predicted labels by finding the index of the maximum value (the highest predicted probability) in each column of A2.\n",
    "\n",
    "        Args:\n",
    "            output_values (np.array): The output values of the neural network.\n",
    "\n",
    "        Returns:\n",
    "            The predictions of the neural network.\n",
    "        \"\"\"\n",
    "        return np.argmax(output_values, axis=0)\n",
    "\n",
    "    def make_predictions(self, X):\n",
    "        \"\"\"\n",
    "        Makes predictions using the neural network.\n",
    "\n",
    "        Args:\n",
    "            X (np.array): The input features.\n",
    "\n",
    "        Returns:\n",
    "            predictions (np.array): The predictions of the neural network.\n",
    "            output_values (np.array): The output values of the neural network.\n",
    "        \"\"\"\n",
    "        self.forward_propagate(X)\n",
    "        output_values = self.output_layer.A\n",
    "        predictions = self.get_predictions(output_values)\n",
    "        return predictions, output_values\n",
    "\n",
    "    def test_prediction(self, index, X, Y):\n",
    "        \"\"\"\n",
    "        Tests a single prediction made by the neural network.\n",
    "\n",
    "        Args:\n",
    "            index (int): The index of the image to test.\n",
    "            X (np.array): The input features.\n",
    "            Y (np.array): The true labels.\n",
    "\n",
    "        Returns:\n",
    "            current_image (np.array): The current image.\n",
    "            output_values (np.array): The output values of the neural network.\n",
    "            label (int): The true value of the image.\n",
    "            is_correct (bool): Whether the prediction was correct.\n",
    "        \"\"\"\n",
    "        current_image = X[:, index, None]\n",
    "        prediction, output_values = self.make_predictions(X[:, index, None])\n",
    "        label = Y[index]\n",
    "\n",
    "        is_correct = prediction == label\n",
    "        return current_image, output_values, label, is_correct"
   ],
   "metadata": {
    "id": "TVQ0m7Satnb7",
    "ExecuteTime": {
     "end_time": "2023-06-07T06:38:59.831466Z",
     "start_time": "2023-06-07T06:38:59.828516Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "*If you're not interested in learning the supplemental math of the neural network, feel free to collapse this cell or skip to the next section.*\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# **Derivative Calculations**\n",
    "Our objective is to find the derivative of the loss function $L_{CE}$ with respect to the inputs of the final layer $Z_i$.\n",
    "\n",
    "You may be familiar with the \"standard\" chain rule:\n",
    "$${\\frac{dz}{dt} = \\frac{dz}{dx} \\cdot \\frac{dx}{dt}}$$\n",
    "\n",
    "However, we will need to tweak it to work for the cross-entropy loss function. This is because the derivative of the cross-entropy loss function with respect to the inputs of the softmax function involves multiple variables. Each output of the softmax function $\\hat{y}_i$ depends on all the inputs $Z_j$, and the loss function depends on all the outputs $\\hat{y}_i$. Changes in any input $Z_i$ can affect all the outputs $\\hat{y}_i$, and consequently, the loss function depends on all the outputs collectively. We can update our chain rule formula to:\n",
    "$${\\frac{dz}{dt} = \\sum_{i=0}^{C-1} \\frac{\\delta z}{\\delta x_i} \\cdot \\frac{dx_i}{dt}}$$\n",
    "\n",
    "Using this updated chain rule, we can define the expression we will start calculating, piece by piece. This expression is the derivative of the loss function $L_{CE}$ with respect to the inputs ${Z_j}$:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta {Z_j}} = \\sum_{i} \\frac{\\delta L_{CE}}{\\delta {\\hat{y}_i}} \\cdot \\frac{\\delta {\\hat{y}_i}}{\\delta {Z_j}}$$\n",
    "\n",
    "In this, $\\frac{\\delta L_{CE}}{\\delta \\hat{y}_i}$ represents the derivative of cross-entropy $L_{CE}$ with respect to the softmax output ${\\hat{y}_i}$, and $\\frac{\\delta \\hat{y}_i}{\\delta {Z_j}}$ represents the derivative of the softmax output ${\\hat{y}_i}$ with respect to the inputs $Z_j$.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Deriving Cross-Entropy**\n",
    "To find $\\frac{\\delta L_{CE}}{\\delta \\hat{y}_i}$, let's consider an example with three classes: Class 0, Class 1, and Class 3. The softmax outputs for the classes are represented as  $\\hat{y}_0$, $\\hat{y}_1$, and $\\hat{y}_2$, and the true label for the input is represented by a one-hot encoded vector $y = [y_0, y_1, y_2]$. For this, the loss function calculation is:\n",
    "$$L_{CE} = -\\sum_{i=0}^{2} y_i \\cdot \\log(\\hat{y}_i)$$\n",
    "$$= -(y_0 \\cdot \\log(\\hat{y}_0)) + (y_1 \\cdot \\log(\\hat{y}_1)) + (y_2 \\cdot \\log(\\hat{y}_2))$$\n",
    "\n",
    "All $y_i = 0$ except for the correct class, where $y_i = 1$. For example, let's say Class 1 is the correct class, then $y = [0, 1, 0]$. Now, let's calculate the derivative of $L_{CE}$ with respect to $\\hat{y}_0$, $\\hat{y}_1$, and $\\hat{y}_2$:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta \\hat{y}_0} = -{\\frac{0}{\\hat{y}_0}} = 0$$\n",
    "$$\\frac{\\delta L_{CE}}{\\delta \\hat{y}_1} = -{\\frac{1}{\\hat{y}_1}} $$\n",
    "$$\\frac{\\delta L_{CE}}{\\delta \\hat{y}_2} = -{\\frac{0}{\\hat{y}_2}} = 0$$\n",
    "\n",
    "When $i$ equals the index of the correct class: $$\\frac{\\delta L_{CE}}{\\delta \\hat{y}_i} = -\\frac{1}{\\hat{y}_i}$$\n",
    "\n",
    "When $i$ does not equal the index of the correct class: $$\\frac{\\delta L_{CE}}{\\delta \\hat{y}_i} = 0$$\n",
    "\n",
    "This reflects the fact that changing the prediction $\\hat{y}_i$ for a class which is not the correct class doesn't affect the cost. From this, we can conclude that:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta \\hat{y}_i} = -{\\frac{y_i}{\\hat{y}_i}}$$\n",
    "\n",
    "Remember, this is only the first piece of the $\\frac{\\delta L_{CE}}{\\delta {Z_i}}$ expression, but we're halfway there!\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Deriving ReLU**\n",
    "This derivative is quite simple, just like calculating ReLU itself. For $x > 0$, the derivative is 1 because the function is just $y = x$. For $x \\leq 0$, the derivative is 0 because the function is constant ($y = 0$).\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Deriving Softmax**\n",
    "Quotient rule:\n",
    "$$\\frac{dy}{dx} = \\frac{v{\\frac{du}{dx}} - u{\\frac{dv}{dx}}}{v^2}$$\n",
    "\n",
    "Softmax function:\n",
    "$$\\hat{y}_i = \\frac{e^{Z_i}}{\\sum_{j=0}^{C-1} e^{Z_j}}$$\n",
    "\n",
    "To get the derivative of softmax with respect to the input, we need to consider two cases: when $i = j$ and when $i \\neq j$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "### **When i = j**\n",
    "This is the case where $i$ and $j$ are the same. We're calculating the derivative of the softmax output $\\hat{y}_i$ with respect to the input $Z_i$.\n",
    "\n",
    "Now, we need to use the quotient rule, but for simplicity, let's say that when $\\sum$ is used in these following expressions, it represents $\\sum_{j=0}^{C-1}$:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_i}} = \\frac{e^{Z_i} \\sum e^{Z_j} - e^{Z_i} e^{Z_i}} {({\\sum e^{Z_j}})^{2}}$$\n",
    "\n",
    "Next, let's expand the denominator to make our expression:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_i}} = \\frac{e^{Z_i} \\sum e^{Z_j} - e^{Z_i} e^{Z_i}} {{\\sum e^{Z_j}}{\\sum e^{Z_j}}}$$\n",
    "\n",
    "Then, factor out $e^{Z_i}$ from the numerator to yield:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_i}} = \\frac{e^{Z_i} (\\sum e^{Z_j} - e^{Z_i})} {{\\sum e^{Z_j}}{\\sum e^{Z_j}}}$$\n",
    "\n",
    "To make the next step more intuitive, we can represent softmax as $\\hat{y}_i$ = $\\frac{e^{Z_i}}{\\sum e^{Z_j}}$.\n",
    "\n",
    "As you can see, since we have $\\frac{e^{Z_i}}{\\sum e^{Z_j}}$ present in our expression as the first terms of the numerator and denominator, we can pull them out as $\\hat{y}_i$:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_i}} = \\hat{y}_i \\frac{\\sum e^{Z_j} - e^{Z_i}} {{\\sum e^{Z_j}}}$$\n",
    "\n",
    "Now, split the fraction into two parts. This results in:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_i}} = \\hat{y}_i \\frac{\\sum e^{Z_j}} {\\sum e^{Z_j}} - \\frac{e^{Z_i}} {{\\sum e^{Z_j}}}$$\n",
    "\n",
    "After cancelling out the ${\\sum e^{Z_j}}$ terms and identifying another $\\hat{y}_i$, this simplifies to:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_i}} = \\hat{y}_i (1 - \\hat{y}_i)$$\n",
    "\n",
    "That's it! That's the derivative of softmax when $i = j$. Now, we have to find when $i â‰  j$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### **When i â‰  j**\n",
    "This is the case where $i$ and $j$ are not the same. We're calculating the derivative of the softmax output $\\hat{y}_i$ with respect to the input $Z_j$.\n",
    "\n",
    "Just as in the case when $i = j$, use the quotient rule and understand $\\sum$ represents $\\sum_{i=0}^{C-1}$:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_j}} = \\frac{0 \\cdot \\sum e^{Z_j} - e^{Z_i} e^{Z_j}} {({\\sum e^{Z_j}})^{2}}$$\n",
    "\n",
    "Next, let's expand the denominator to make our expression:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_j}} =\\frac{-e^{Z_i} e^{Z_j}} {{\\sum e^{Z_j}}{\\sum e^{Z_j}}}$$\n",
    "\n",
    "Next, split the fraction into two parts. This results in:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_j}} =  -\\frac{e^{Z_i}} {\\sum e^{Z_j}} \\cdot \\frac{e^{Z_j}} {\\sum e^{Z_j}}$$\n",
    "\n",
    "Using the same logic from the $i = j$ case, we can express this as:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_j}} =  -\\hat{y}_i \\cdot \\hat{y}_j$$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### **Combined Expression**\n",
    "Now, we can combine the two cases into one, clean expression. Even though both cases will be put together, remember that the first portion represents when $i = j$ and the second portion represents when $i â‰  j$. We'll address this later, but keep this in mind for now. Putting both parts together, we have:\n",
    "$$\\frac{\\delta \\hat{y}_i}{\\delta {Z_j}} =  \\hat{y}_i (1 - \\hat{y}_i) - \\hat{y}_i \\hat{y}_j$$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Total Calculation**\n",
    "In this, $i$ is used to index the class for which we're computing the derivative of, while $j$ is used to index over all possible classes in the denominator.\n",
    "\n",
    "Recall the cross-entropy loss function:\n",
    "$$L_{CE} = -\\sum_{i=0}^{C-1} y_i \\cdot \\log(\\hat{y}_i)$$\n",
    "\n",
    "As we found earlier, the derivative of $L_{CE}$ with respect to $\\hat{y}_i$ is:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta \\hat{y}_i} = -\\frac{y_i}{\\hat{y}_i}$$\n",
    "\n",
    "Now, we can use the softmax and cross-entropy derivatives to fill in the expression for the derivative of the loss function $L_{CE}$ with respect to the inputs ${Z_j}$:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta {Z_j}} = \\sum_{i} \\frac{\\delta L_{CE}}{\\delta {\\hat{y}_i}} \\cdot \\frac{\\delta {\\hat{y}_i}}{\\delta {Z_j}}$$\n",
    "$$= -\\sum_{i} \\frac{y_i}{\\hat{y}_i} \\cdot [\\hat{y}_i (1 - \\hat{y}_i) - \\hat{y}_i \\hat{y}_j]$$\n",
    "\n",
    "Remember, we haven't made a notational distinction between the two cases where $i = j$ and $i â‰  j$, so we'll address that now:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta {Z_j}} = -\\sum_{i=j} \\frac{y_i}{\\hat{y}_i} \\cdot \\hat{y}_i (1 - \\hat{y}_i) + \\sum_{iâ‰ j} \\frac{y_i}{\\hat{y}_i} \\cdot \\hat{y}_i \\hat{y}_j$$\n",
    "$$= -\\sum_{i=j} y_i \\cdot (1 - \\hat{y}_i) + \\sum_{iâ‰ j} {y}_i \\hat{y}_j$$\n",
    "$$= -\\sum_{i=j} y_i + y_i \\hat{y}_i + \\sum_{iâ‰ j} {y}_i \\hat{y}_j$$\n",
    "\n",
    "In the left expression, $i = j$. Therefore, we can simplify $\\sum_{i=j} {y}_i$ to ${y}_j$. Also, we are able to use $y_i$ and $y_j$ interchangeably,:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta {Z_j}} = -y_j + y_j \\hat{y}_j + \\sum_{iâ‰ j} {y}_i \\hat{y}_j$$\n",
    "\n",
    "Now, we need to combine the two cases of $i = j$ and $i â‰  j$ together. into one summation:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta {Z_j}} = -y_j + \\sum_{i} {y}_i \\hat{y}_j$$\n",
    "\n",
    "Recall that $y$ is one-hot encoded, so all $y_i$ are 0 except for the correct class, where it equals 1. Because of this, $\\sum_{i} {y}_i \\hat{y}_j$ simplifies to just $1 \\cdot \\hat{y}_j$:\n",
    "$$\\frac{\\delta L_{CE}}{\\delta {Z_j}} = -y_j + 1 \\cdot \\hat{y}_j$$\n",
    "$$= \\hat{y}_j - y_j$$\n",
    "\n",
    "We're done! Now we have the derivative of the loss function with respect to the inputs of softmax. This will be crucial for our backpropagation implementation.\n",
    "\n",
    "This is why cross-entropy and softmax are commonly used in conjunction, the final representation is quite simple!\n",
    "\n",
    "Note, the result of $\\frac{\\delta L_{CE}}{\\delta {Z_j}} = \\sum_{i} \\frac{\\delta L_{CE}}{\\delta {\\hat{y}_i}} \\cdot \\frac{\\delta {\\hat{y}_i}}{\\delta {Z_j}}$ is only explicitly used to calculate the variable $Z^{[2]}$ in the backpropagation function in our code. Although $Z^{[2]}$ is used to calculate other variables, all of this math was mostly for $Z^{[2]}$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Results**\n",
    "This is the exciting part! We can finally see our results!\n",
    "\n",
    "First, we have to actually train our model (we'll keep it separated from the other code because it takes a while to run, just in case you wanted to tweak any of the subsequent code). Remember, these results are from the training session, not the testing session. Afterward, we'll benchmark our neural network by running it with the validation data we grabbed from our training data and set aside as our \"testing\" data, and see how the accuracy matches up. Ideally, we want them to be similar, but sometimes it varies.\n",
    "\n",
    "Then, we'll display some correct and incorrect predictions from the training data, and some graphs to show the progress over time. I enjoy looking at the incorrect predictions because I try to find what could've caused our model to make a mistake.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "class Visualizer:\n",
    "    \"\"\"\n",
    "    A class to help visualize the results of our neural network.\n",
    "\n",
    "    Attributes:\n",
    "        nn (NeuralNetwork): The neural network we want to visualize.\n",
    "    \"\"\"\n",
    "    def __init__(self, neural_network):\n",
    "        self.nn = neural_network\n",
    "\n",
    "    def display_predictions(self, n, display_correct=True):\n",
    "        \"\"\"\n",
    "        Displays n predictions from the neural network.\n",
    "\n",
    "        Args:\n",
    "            n (int): The number of predictions to display.\n",
    "            display_correct (bool): Whether to display correct or incorrect predictions.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        count = 0\n",
    "        X, Y = self.nn.X, self.nn.Y\n",
    "        while count < n:\n",
    "            random_index = np.random.randint(0, X.shape[1])\n",
    "            current_image, output_values, label, is_correct = self.nn.test_prediction(random_index, X, Y)\n",
    "\n",
    "            if is_correct == display_correct:\n",
    "                predictions.append((output_values, label, current_image))\n",
    "                count += 1\n",
    "\n",
    "        num_rows = n // 5 if n % 5 == 0 else n // 5 + 1\n",
    "        fig, axes = plt.subplots(nrows=num_rows, ncols=5, figsize=(15, num_rows * 3))\n",
    "\n",
    "        for i, (prediction, label, img) in enumerate(predictions):\n",
    "            row = i // 5\n",
    "            col = i % 5\n",
    "            if num_rows == 1:  # Special case to handle indexing when there is only 1 row\n",
    "                ax = axes[col]\n",
    "            else:\n",
    "                ax = axes[row, col]\n",
    "            ax.imshow(img.reshape((28, 28)) * 255, cmap='gray')\n",
    "            ax.set_title(f\"Prediction: {np.argmax(prediction)}\\nTrue Label: {label}\")\n",
    "            ax.axis('off')\n",
    "\n",
    "        if display_correct:\n",
    "            print('Correct Predictions:\\n')\n",
    "        else:\n",
    "            print('Incorrect Predictions:\\n')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def graph_accuracy(self):\n",
    "        \"\"\"\n",
    "        Graphs the accuracy of the neural network over the iterations.\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(self.nn.iteration_list, self.nn.accuracy_list)\n",
    "        ax.set_xlabel('Iteration')\n",
    "        ax.set_ylabel('Accuracy (%)')\n",
    "        ax.set_title('Accuracy Over Time')\n",
    "        plt.show()\n",
    "\n",
    "    def graph_cost(self):\n",
    "        \"\"\"\n",
    "        Graphs the cost of the neural network over the iterations.\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(self.nn.iteration_list, self.nn.cost_list)\n",
    "        ax.set_xlabel('Iteration')\n",
    "        ax.set_ylabel('Cost')\n",
    "        ax.set_title('Cost Over Time')\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T06:38:59.845988Z",
     "start_time": "2023-06-07T06:38:59.832236Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Accuracy: 7.339%\n",
      "Cost: 2.794\n",
      "\n",
      "Iteration: 100\n",
      "Accuracy: 72.639%\n",
      "Cost: 0.805\n",
      "\n",
      "Iteration: 200\n",
      "Accuracy: 82.837%\n",
      "Cost: 0.546\n",
      "\n",
      "Iteration: 300\n",
      "Accuracy: 86.012%\n",
      "Cost: 0.459\n",
      "\n",
      "Iteration: 400\n",
      "Accuracy: 87.483%\n",
      "Cost: 0.416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "layers = {\n",
    "    'input': Layer(nodes=784),\n",
    "    'hidden1': Layer(nodes=10, activation='relu'),\n",
    "    'output': Layer(nodes=10, activation='softmax')\n",
    "}\n",
    "\n",
    "network = NeuralNetwork(train_data.X, train_data.Y, layers=layers)\n",
    "network.optimizer(iterations=500, print_interval=100, graph_interval=50, alpha=0.20)"
   ],
   "metadata": {
    "id": "Yx7HFUqQtnb7",
    "ExecuteTime": {
     "end_time": "2023-06-07T06:39:41.874848Z",
     "start_time": "2023-06-07T06:38:59.849315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data Accuracy: 88.500%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the model with the validation data\n",
    "validation_predictions = network.make_predictions(validate_data.X)[0]\n",
    "validation_accuracy_percent = network.get_accuracy(validation_predictions, validate_data.Y) * 100\n",
    "print(f'Validation Data Accuracy: {validation_accuracy_percent:.3f}%\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T06:39:41.925262Z",
     "start_time": "2023-06-07T06:39:41.878959Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1500x600 with 10 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect Predictions:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1500x600 with 10 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAHFCAYAAAAHcXhbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQ6UlEQVR4nO3deVxU5f4H8M8MMMM2jCAwA4ps4oq7hpIJmdBVKb22mf3K8lZ6tZSsTLPFLEHp5jWzm61qlultscx7LbAM65KFu4m5oqKCuLAM2wzMPL8/kJERVAZnODPweb9e55VzzpkzXzjlfHqe5zyPTAghQEREROSk5FIXQERERHQjGGaIiIjIqTHMEBERkVNjmCEiIiKnxjBDRERETo1hhoiIiJwawwwRERE5NYYZIiIicmoMM0REROTUGGaIJLZ06VLIZDJER0dLXYpTysvLwxNPPIHIyEi4u7vD19cX8fHx+PTTT+FIE5zPmzcPMpnsult8fDyOHz8OmUyGlStXSl02kVOQcTkDImn17dsXe/bsAQBs27YNMTExElfkPP73v/8hKSkJ3t7eePbZZ9G7d2+UlJTg3//+N9asWYP77rsPa9asgVwu/f+3nTp1CqdOnTK/zs/Px7hx4/Dkk09iwoQJ5v0+Pj6IjIzErl27EBkZiYCAACnKJXIqrlIXQNSWbd++HXv27MHo0aPxn//8Bx9++KHDhpmKigp4enpKXYZZcXExxo0bB7Vajd9++w0ajcZ8bMyYMejduzdmz56Nvn37Yvbs2S1Wl9FoRE1NDZRKpcX+jh07omPHjubXx48fBwB06tQJgwcPbnCdxvYRUeOk/98Vojbsww8/BAAsXLgQsbGxWLt2LSoqKhqcd/r0aTz++OMICQmBQqFAcHAw7r77bpw9e9Z8TnFxMZ5++mlERERAqVQiMDAQo0aNwp9//gkA+OmnnyCTyfDTTz9ZXLuxLo2HH34Y3t7e2LdvHxITE6FSqXDbbbcBADIyMjBmzBh07NgR7u7u6Ny5MyZPnozz5883qPvPP//E/fffD41GA6VSiU6dOuGhhx6CXq/H8ePH4erqitTU1Abv27p1K2QyGT7//POr/u4++OADFBYWYuHChRZBps6sWbPQrVs3vP7666iursa5c+egUCjw4osvNlqnTCbD0qVLzfsKCgowefJkdOzYEQqFAuHh4XjllVdQU1PT4HeXlpaG1157DeHh4VAqldiyZctV626Kxu5JXTfV3r17cc8990CtVsPPzw8zZ85ETU0NDh48iL/85S9QqVQICwtDWlpag+uWlpbimWeeQXh4OBQKBTp06IDk5GSUl5ffUL1EUmPLDJFEKisr8dlnn2HQoEGIjo7GpEmT8Oijj+Lzzz/HxIkTzeedPn0agwYNQnV1NZ5//nn07t0bFy5cwPfff4+ioiJoNBrodDoMHToUx48fx3PPPYeYmBiUlZVh69atyM/PR7du3ayuz2Aw4M4778TkyZMxe/Zs85f40aNHMWTIEDz66KNQq9U4fvw4Fi9ejKFDh2Lfvn1wc3MDAOzZswdDhw6Fv78/5s+fj6ioKOTn52PDhg0wGAwICwvDnXfeieXLl2PWrFlwcXExf/ayZcsQHByMv/71r1etLyMjAy4uLrjjjjsaPS6TyXDnnXciLS0NO3bswODBg5GUlIRVq1bhlVdeseh6WrFiBRQKBR544AEAtUHmpptuglwux0svvYTIyEj8+uuveO2113D8+HGsWLHC4rOWLl2KLl264B//+Ad8fHwQFRVl9e+7qe6991783//9HyZPnoyMjAykpaWhuroamzdvxtSpU/HMM89gzZo1eO6559C5c2eMGzcOQG3LWlxcHE6dOmX+92j//v146aWXsG/fPmzevBkymcxudRPZlSAiSXz88ccCgFi+fLkQQgidTie8vb3FLbfcYnHepEmThJubm8jJybnqtebPny8AiIyMjKues2XLFgFAbNmyxWJ/bm6uACBWrFhh3jdx4kQBQHz00UfX/BlMJpOorq4WJ06cEADEN998Yz42fPhw0a5dO1FYWHjdmtavX2/ed/r0aeHq6ipeeeWVa352t27dhFarveY577zzjgAg1q1bJ4QQYsOGDQKASE9PN59TU1MjgoODxV133WXeN3nyZOHt7S1OnDhhcb1//OMfAoDYv3+/EOLy7y4yMlIYDIZr1nKluve+/vrrVz1W/568/PLLAoB44403LM7t27evACC++uor877q6moREBAgxo0bZ96Xmpoq5HK5yM7Otnj/F198IQCI//73v1bVT+RI2M1EJJEPP/wQHh4eGD9+PADA29sb99xzD37++WccPnzYfN6mTZtw6623onv37le91qZNm9ClSxeMGDHCpjXeddddDfYVFhZiypQpCAkJgaurK9zc3BAaGgoAOHDgAIDaVoDMzEzce++91xzAGh8fjz59+uDtt98271u+fDlkMhkef/zxG65fXHq+oa7FYeTIkdBqtRYtK99//z3OnDmDSZMmmfdt3LgRt956K4KDg1FTU2PeRo4cCQDIzMy0+Jw777zT3CJlb0lJSRavu3fvDplMZq4NAFxdXdG5c2ecOHHCvG/jxo2Ijo5G3759LX6m22+/vdHuRyJnwjBDJIEjR45g69atGD16NIQQKC4uRnFxMe6++24AwEcffWQ+99y5cxYDRxvTlHOs5enpCR8fH4t9JpMJiYmJ+OqrrzBr1iz88MMP+P3337Ft2zYAtV1nAFBUVASj0dikmqZPn44ffvgBBw8eRHV1Nd5//33cfffd0Gq113xfp06dcO7cuWuO96gbZBsSEgKg9kv+wQcfxPr161FcXAwAWLlyJYKCgnD77beb33f27Fl8++23cHNzs9h69uwJAA3GBwUFBV3357QVPz8/i9cKhQKenp5wd3dvsL+qqsr8+uzZs9i7d2+Dn0mlUkEI0eiYJyJnwTEzRBL46KOPIITAF198gS+++KLB8VWrVuG1116Di4sLAgICLB7pbUxTzqn7stPr9Rb7r/Yl1tj4iT/++AN79uzBypUrLcb1HDlyxOI8Pz8/uLi4XLcmAJgwYQKee+45vP322xg8eDAKCgowbdq0674vISEB6enp+Pbbb82tW/UJIbBhwwb4+flhwIAB5v2PPPIIXn/9daxduxb33XcfNmzYgOTkZIsxO/7+/ujduzcWLFjQ6GcHBwdbvHaGsSb+/v7w8PCwCMpXHidyVgwzRC3MaDRi1apViIyMxAcffNDg+MaNG/HGG29g06ZNSEpKwsiRI7F69WocPHgQXbt2bfSaI0eOxEsvvYQff/wRw4cPb/ScsLAwAMDevXstWiE2bNjQ5NrrvrSvfOz43XfftXjt4eGBuLg4fP7551iwYME1vyjd3d3x+OOPY9myZcjKykLfvn1x8803X7eWRx99FK+//jrmzJmD4cOHIzAw0OJ4Wloa/vzzTyxcuNCiC6h79+6IiYnBihUrYDQaodfr8cgjj1i8NykpCf/9738RGRkJX1/f69biDJKSkpCSkoL27dsjPDxc6nKIbIphhqiFbdq0CWfOnMGiRYsQHx/f4Hh0dDSWLVuGDz/8EElJSZg/fz42bdqEYcOG4fnnn0evXr1QXFyM7777DjNnzkS3bt2QnJyMdevWYcyYMZg9ezZuuukmVFZWIjMzE0lJSbj11luh1WoxYsQIpKamwtfXF6Ghofjhhx/w1VdfNbn2bt26ITIyErNnz4YQAn5+fvj222+RkZHR4Ny6J5xiYmIwe/ZsdO7cGWfPnsWGDRvw7rvvQqVSmc+dOnWq+amjxgJeY9q1a4evvvoKSUlJGDBgAJ599ln06dMHpaWlWLduHT799FPcd999ePbZZxu8d9KkSZg8eTLOnDmD2NjYBiFx/vz5yMjIQGxsLKZPn46uXbuiqqoKx48fx3//+18sX77c5t169pacnIwvv/wSw4YNw1NPPYXevXvDZDLh5MmTSE9Px9NPP+2wcxwRXZeUo4+J2qKxY8cKhUJxzad8xo8fL1xdXUVBQYEQQoi8vDwxadIkodVqhZubmwgODhb33nuvOHv2rPk9RUVFYsaMGaJTp07Czc1NBAYGitGjR4s///zTfE5+fr64++67hZ+fn1Cr1eL//u//xPbt2xt9msnLy6vR2nJyckRCQoJQqVTC19dX3HPPPeLkyZMCgHj55ZcbnHvPPfeI9u3bC4VCITp16iQefvhhUVVV1eC68fHxws/PT1RUVDTl12h28uRJMW3aNBERESEUCoVQq9Vi2LBh4pNPPhEmk6nR95SUlAgPDw8BQLz//vuNnnPu3Dkxffp0ER4eLtzc3ISfn58YMGCAmDt3rigrKxNCXPuJpOtp7tNM586dszj3avcqLi5O9OzZ02JfWVmZeOGFF0TXrl3Nv6tevXqJp556yvzvGpEz4nIGRCS5wsJChIaG4sknn2x0sjciomthNxMRSebUqVM4duwYXn/9dcjlcsyYMUPqkojICfHRbCKSzAcffID4+Hjs378fn376KTp06CB1SUTkhNjNRERERE6NLTNERETk1BhmiIiIyKkxzBAREZFTa/VPM5lMJpw5cwYqlcopphwnIiKi2iVJdDodgoODIZdfu+2l1YeZM2fOmBeZIyIiIueSl5d33Rm3W32YqZsyPS8vr8EKwEREROSYSktLERISYrH0ydW0+jBT17Xk4+PDMENERORkmjJEhAOAiYiIyKlJGmZ0Oh2Sk5MRGhoKDw8PxMbGIjs723xcCIF58+YhODgYHh4e5plCiYiIiOpIGmYeffRRZGRkYPXq1di3bx8SExMxYsQInD59GgCQlpaGxYsXY9myZcjOzoZWq0VCQgJ0Op2UZRMREZEDkWw5g8rKSqhUKnzzzTcYPXq0eX/fvn2RlJSEV199FcHBwUhOTsZzzz0HANDr9dBoNFi0aBEmT57cpM8pLS2FWq1GSUkJx8wQERE5CWu+vyVrmampqYHRaIS7u7vFfg8PD/zyyy/Izc1FQUEBEhMTzceUSiXi4uKQlZV11evq9XqUlpZabERERNR6SRZmVCoVhgwZgldffRVnzpyB0WjEJ598gt9++w35+fkoKCgAAGg0Gov3aTQa87HGpKamQq1WmzfOMUNERNS6STpmZvXq1RBCoEOHDlAqlVi6dCkmTJgAFxcX8zlXPpIlhLjmY1pz5sxBSUmJecvLy7Nb/URERCQ9ScNMZGQkMjMzUVZWhry8PPz++++orq5GeHg4tFotADRohSksLGzQWlOfUqk0zynDuWWIiIhaP4eYZ8bLywtBQUEoKirC999/jzFjxpgDTUZGhvk8g8GAzMxMxMbGSlgtERERORJJZwD+/vvvIYRA165dceTIETz77LPo2rUrHnnkEchkMiQnJyMlJQVRUVGIiopCSkoKPD09MWHCBCnLJiIiIgciaZgpKSnBnDlzcOrUKfj5+eGuu+7CggUL4ObmBgCYNWsWKisrMXXqVBQVFSEmJgbp6elNWqeBiIiI2gbJ5plpKZxnhoiIyPlY8/3d6heaJCIiItuqMZpQVWNCVbURlQYjvJWu8PVSSFYPwwwREZGTE0LAYDShymBCVY2xNmRUG1FVbTL/WX/pde3+y3/WV1/t/Hrn1hhRaTDVnltjRLXRslNn+vDOmJnYVaKfnmGGiIjI7vQ1RpRV1aBMXwPdpX+W62ssAkTVFSGj6opjje2rqjGh0lAbMKQaNKJ0lUPq8SoMM0RERI0wmQQqqo0orxdAagNJ9RWva6Cr9+eyqtrX5frLrw1GU4vVLZcBHm4ucDdvcri7udTbJ7c4ZnnupeOuLvBQXP6zu8KlwT4PhQsULnLI5VefyLalMMwQEVGrUm00WQaQKwNGVf3wUW3RWlI/kJQZamze2uGlcIG3uyu8la7wUrrWCxmWgUNZP2S4yi+FCBco6wKF66XzL4UMdze5OXC4uciuOVN+a8QwQ0REDkMIgapqE4orDSiprEZxRTVKKqtRUvfPymqUVlVfEUjqd99Uo6ratq0gLnIZvJW1AUR1KYjUBRLz5l7/uNsVr2uPeylc4eIArRitEcMMERHZnKHGZA4ftZtlOCmuqEbppWPFlZb7bNUlo3SVNxI+3K4ZSFT197u7QqV0g7ubvM21dDgbhhkiImqUySSgq6pp2EpSbyuusDxWeimcVBiMN/TZLnIZ2nm4Qe3hBh8PN7TzrP1zu0uv61pAvJQul1tD6rWEeCldoXB1iBV7qAUwzBARtXI1RhMulhtwvszQaCtJXetI6RX7Squqb3jMiI+7K9TmIKKA2sPN/LounDTY56mAl8KFrSHUZAwzREROSAiBkspqnNPpa7cy/eU/13t9vkyPC+WGGwolngoXc9C4HDguBw+fK4JJ3TGVuxvHiFCLYJghInIgFYYanNcZcK6sqtFwUv/1lROXXYuLXAZfT4VFd02DLhzP+oFFYf4zu2vI0THMEBHZWbXRhAtlhksh5NohpdzKsSbtPN0Q4K1EgOrS5q2E/6V/mveplPD1VLCVhFothhkiomYwmQSK63XznC+7egvKxXKDVdd2d5MjUOVuDif1Q0n91+29FVC6utjpJyRyHgwzRESNKNPX4NBZHQ6f1SHvYmWDoHK+TI8aU9O7eVzlMvjXCyL+3op64cTdIrBw8CuRdRhmiKhNq6o24khhGQ6d1eHgWR0OFehw6GwZThdXNun9vp5ujbaa1L6+HFLaebg5xLTvRK0RwwwRtQmGGhOOXyjHwQIdDp2t28pw4kI5rtbAEqhSoqtWhbD2XghUXRFUVEq091JycCyRA2CYIaJWxWgSOHmx4orQosOxc+VX7Rby9XRDF40KXbUqRGlU6KpRoYvGG+08FS1cPRE1B8MMETklIQROF1eaW1gOFdR2Ex0pLIO+pvHp8L2Vruii8UYXjapeePFGgLeSY1SInBjDDBE5NCEEzun0teNZrggtZfqaRt/j7iZH58Da0NJVo0IXbW14CVa7M7QQtUIMM0TkMIrKDeZuIXN4OatDcUV1o+e7ucgQ4e+NLloVumq8zV1EIX6enFOFqA1hmCGiFqerqsbhwsutLIfPluHgWR3O6fSNni+XAWHtvS51D9WFFxXC/L3g5sIBuERtHcMMEdlN3WPPBwt0OFTYtMeeO/p61BvTUttVFBngDXc3Tg5HRI1jmCEim6k0GPH78Yv4+dA5/Hz4PA4V6q66wGHdY8/m1hZN7ZNE3kr+tURE1uHfGkTUbEIIHMjX4efDteHl9+MXYbjiSSI+9kxE9sYwQ0RWKdRV4ZfD5/Hzpe18meU4lyC1O4ZFBeCWLv64KcwPASo+9kxE9sUwQ0TXVFVtxPbjRfj58DlsPXweB/JLLY57uLlgSGR73BLlj1uiAhAZ4MXwQkQtimGGiCwIIXDobJk5vPx27EKDSeiiO/jglqgADIsKQP/Qdly5mYgkxTBDRLhQpscvR85j66Hz+PnwORRe8Yi0xkeJW6ICcEuUP4Z29kd7b6VElRIRNcQwQ9QG6WuM2HGi6NK4l3P447Rl15HSVY6YiPYYFuWPYV0CEBXoza4jInJYDDNEbYAQAkfPlZlbXrYdu4jKaqPFOd2DfDDs0riXgWG+nNeFiJwGwwxRK1VUbsAvR86bH5vOL6myOO7vrawNL138cXNnfwSq3CWqlIjoxkgaZmpqajBv3jx8+umnKCgoQFBQEB5++GG88MILkMtrpygXQuCVV17Be++9h6KiIsTExODtt99Gz549pSydyOEYakzYdfJy19He0yUWE9YpXOW4KcwPw7rUtr5006rYdURErYKkYWbRokVYvnw5Vq1ahZ49e2L79u145JFHoFarMWPGDABAWloaFi9ejJUrV6JLly547bXXkJCQgIMHD0KlUklZPpGkhBDIPV9uDi+/Hr2AcoNl11FXjar2kekuAbgpzA8eCnYdEVHrIxPiapON219SUhI0Gg0+/PBD87677roLnp6eWL16NYQQCA4ORnJyMp577jkAgF6vh0ajwaJFizB58uTrfkZpaSnUajVKSkrg4+Njt5+FqCWUVFQj6+h5bL0UYE4VWa5x5OelMM/3MrSzP7Rqdh0RkXOy5vtb0paZoUOHYvny5Th06BC6dOmCPXv24JdffsGSJUsAALm5uSgoKEBiYqL5PUqlEnFxccjKymo0zOj1euj1lx8rLS0tbXAOkbOoMZqwO6/YHF725BXDVO9/P9xcZBgY6odbuvhjWFQAegT5QC5n1xERtS2ShpnnnnsOJSUl6NatG1xcXGA0GrFgwQLcf//9AICCggIAgEajsXifRqPBiRMnGr1mamoqXnnlFfsWTmRHp4sr8eOfhfj5UG3XkU5fY3G8c6A3bomqDS8xEX7wVHAcPxG1bZL+Lbhu3Tp88sknWLNmDXr27Indu3cjOTkZwcHBmDhxovm8KwcpCiGuOnBxzpw5mDlzpvl1aWkpQkJC7PMDENlQcYUBSzYfxuptJ2Cs1/zSztMNN3f2Nz82HdzOQ8IqiYgcj6Rh5tlnn8Xs2bMxfvx4AECvXr1w4sQJpKamYuLEidBqtQBgftKpTmFhYYPWmjpKpRJKJWcnJedRYzTh099O4p+bD6G4ohoAMCDUF7d2DcAtUQGI7qCGC7uOiIiuStIwU1FRYX4Eu46LiwtMptp1YMLDw6HVapGRkYF+/foBAAwGAzIzM7Fo0aIWr5fI1n4+fA7zv83B4cIyAEAXjTdeSuqJoVH+EldGROQ8JA0zd9xxBxYsWIBOnTqhZ8+e2LVrFxYvXoxJkyYBqO1eSk5ORkpKCqKiohAVFYWUlBR4enpiwoQJUpZOdENyz5djwX9ysPlAIQDA19MNMxO64P6bOsHVRX6ddxMRUX2Shpm33noLL774IqZOnYrCwkIEBwdj8uTJeOmll8znzJo1C5WVlZg6dap50rz09HTOMUNOqbSqGm/9cBgrs46j2ijgIpfhoSGhSL6tC9SeblKXR0TklCSdZ6YlcJ4ZcgRGk8C67Dy8kX4QF8oNAIC4LgF4Mak7OgcymBMRXclp5pkhagt+PXoB8zfm4EB+7ZxHEQFeeHF0D9zaLVDiyoiIWgeGGSI7ybtYgZT/HsCmP2rnS1K5uyJ5RBc8NCQUbhwXQ0RkMwwzRDZWpq/Bv7YcwQe/5MJQY4JcBkyI6YSZCV3h56WQujwiolaHYYbIRkwmgS93nkLa9wdxTle7pEZsZHu8dEcPdNNyvBYRkb0wzBDZwI4TF/HKtznYe6oEABDa3hPPj+qOxB6aq85WTUREtsEwQ3QDzhRXYuGmP7FhzxkAgLfSFU8M74xHbg6D0tVF4uqIiNoGhhmiZqg0GPHu1qNYnnkUVdUmyGTAvQNC8PTtXRCocpe6PCKiNoVhhsgKQghs2HMGizb9iTMlVQCAQWG+ePmOnojuoJa4OiKitolhhqiJ9uQVY/7GHOw4UQQA6NDOA3NGdcPoXkEcF0NEJCGGGaLrKCytwqLvDuLLnacAAB5uLpgaH4nHhkXA3Y3jYoiIpMYwQ3QVVdVGfPhLLt7ecgQVBiMAYFy/Dpj1l27QqjkuhojIUTDMEF1BCIHv/ijAgv8ewKmiSgBA35B2ePmOHujXyVfi6oiI6EoMM0T17D9Tgvnf5uC33IsAAK2PO54b2RVj+nSAXM5xMUREjohhhgjA+TI93kg/iLXZeRACULrKMXlYBKbER8JTwf9MiIgcGf+WpjbNUGPCqqzjWPrDYej0NQCApN5BmD2yGzr6ekpcHRERNQXDDLVJQgj8cKAQC/57ALnnywEA0R188FJST9wU7idxdUREZA2GGWpzDp3V4dWNOfj58HkAgL+3ErNu74q7B3TkuBgiIifEMENtRlG5Af/cfAif/nYSRpOAwkWOSUPDMe3WSKjc3aQuj4iImolhhlq9aqMJn247gX9uPoySymoAwO09NXh+VHeEtveSuDoiIrpRDDPUqmUeOodXN+bgSGEZAKCbVoWXknogtrO/xJUREZGtMMxQq3TsXBkW/OcAfvizEADg56XAzIQuGD8oBK4ucomrIyIiW2KYoValpLIab/1wGCuzjqPGJOAql2FibBim3xYFtQfHxRARtUYMM9QqCCHw7+15WPTdQVwsNwAAbu0agBeSeiAywFvi6oiIyJ4YZqhV+HLnaTz35T4AQGSAF15M6oH4roESV0VERC2BYYac3jmdHq9uzAEAPHZLOGb9pRvcOC6GiKjNYJghpzfv2/0oqaxGz2AfPPeXbhzgS0TUxvBvfXJqGTln8Z+9+XCRy7Dort4MMkREbRD/5ienVVpVjRe//gMA8Ogt4YjuoJa4IiIikgLDDDmttO/+REFpFULbeyL5ti5Sl0NERBJhmCGn9HvuRXyy7SQAIHVcL3goXCSuiIiIpCJpmAkLC4NMJmuwTZs2DUDt3CHz5s1DcHAwPDw8EB8fj/3790tZMjmAqmojZn+5FwAwflAIYiO5NAERUVsmaZjJzs5Gfn6+ecvIyAAA3HPPPQCAtLQ0LF68GMuWLUN2dja0Wi0SEhKg0+mkLJsktuzHIzh2vhwBKiXmjOwudTlERCQxScNMQEAAtFqtedu4cSMiIyMRFxcHIQSWLFmCuXPnYty4cYiOjsaqVatQUVGBNWvWSFk2SehAfimWZx4FALw6pifUnlyigIiorXOYMTMGgwGffPIJJk2aBJlMhtzcXBQUFCAxMdF8jlKpRFxcHLKysiSslKRiNAk89+Ve1JgEbu+pwV+ig6QuiYiIHIDDTJr39ddfo7i4GA8//DAAoKCgAACg0WgsztNoNDhx4sRVr6PX66HX682vS0tLbV8sSWLF/3Kx91QJVO6umD8mWupyiIjIQThMy8yHH36IkSNHIjg42GK/TCazeC2EaLCvvtTUVKjVavMWEhJil3qpZZ28UIF/pB8EADw/qjs0Pu4SV0RERI7CIcLMiRMnsHnzZjz66KPmfVqtFsDlFpo6hYWFDVpr6pszZw5KSkrMW15enn2KphYjhMDz6/ehqtqEwRF+GD+IAZWIiC5ziDCzYsUKBAYGYvTo0eZ94eHh0Gq15iecgNpxNZmZmYiNjb3qtZRKJXx8fCw2cm5f7DiFX46ch9JVjtRxva/ZMkdERG2P5GNmTCYTVqxYgYkTJ8LV9XI5MpkMycnJSElJQVRUFKKiopCSkgJPT09MmDBBwoqpJZ3T6fHafw4AAJJHdEG4v5fEFRERkaORPMxs3rwZJ0+exKRJkxocmzVrFiorKzF16lQUFRUhJiYG6enpUKlUElRKUqi/IvZjt4RLXQ4RETkgmRBCSF2EPZWWlkKtVqOkpIRdTk4mI+csHvt4O1zkMnwz7WYuJElE1IZY8/3tEGNmiK7EFbGJiKipGGbIIS3adHlF7KdGcEVsIiK6OoYZcji/517Ep79dXhHb3Y0rYhMR0dUxzJBD4YrYRERkLYYZcihcEZuIiKzFMEMOgytiExFRczDMkEPgithERNRcDDPkELgiNhERNRfDDEmu/orYc7kiNhERWYlhhiR15YrY93FFbCIishLDDEmKK2ITEdGNYpghyXBFbCIisgWGGZIMV8QmIiJbYJghSWTknMV/9ubDRS7Dort6w9WF/yoSEVHz8BuEWhxXxCYiIltimKEWxxWxiYjIlhhmqEVxRWwiIrI1hhlqMVwRm4iI7IFhhloMV8QmIiJ7YJihFsEVsYmIyF4YZsju6q+I/ZeeWq6ITURENsUwQ3ZXf0XsV8b0lLocIiJqZRhmyK64IjYREdkbwwzZDVfEJiKilsAwQ3ZTf0XshVwRm4iI7IRhhuyi/orYTyV0QRhXxCYiIjthmCG7qL8i9qNDuSI2ERHZD8MM2RxXxCYiopbEbxmyKa6ITURELY1hhmyKK2ITEVFLY5ghm+GK2EREJAXJw8zp06fxf//3f2jfvj08PT3Rt29f7Nixw3xcCIF58+YhODgYHh4eiI+Px/79+yWsmBrDFbGJiEgqkoaZoqIi3HzzzXBzc8OmTZuQk5ODN954A+3atTOfk5aWhsWLF2PZsmXIzs6GVqtFQkICdDqddIVTAxYrYo/iithERNRyXKX88EWLFiEkJAQrVqww7wsLCzP/WQiBJUuWYO7cuRg3bhwAYNWqVdBoNFizZg0mT57c0iVTIxqsiO3BFbGJiKjlSNoys2HDBgwcOBD33HMPAgMD0a9fP7z//vvm47m5uSgoKEBiYqJ5n1KpRFxcHLKyshq9pl6vR2lpqcVG9lNjNHFFbCIikpSkYebYsWN45513EBUVhe+//x5TpkzB9OnT8fHHHwMACgoKAAAajcbifRqNxnzsSqmpqVCr1eYtJITrAdnTyqzjXBGbiIgkJWmYMZlM6N+/P1JSUtCvXz9MnjwZjz32GN555x2L865c00cIcdV1fubMmYOSkhLzlpeXZ7f62zquiE1ERI5A0jATFBSEHj16WOzr3r07Tp6sfbxXq9UCQINWmMLCwgatNXWUSiV8fHwsNrK9+itiD4lozxWxiYhIMpKGmZtvvhkHDx602Hfo0CGEhoYCAMLDw6HVapGRkWE+bjAYkJmZidjY2BatlSzVXxE7dVwvrohNRESSkfRppqeeegqxsbFISUnBvffei99//x3vvfce3nvvPQC13UvJyclISUlBVFQUoqKikJKSAk9PT0yYMEHK0ts0rohNRESORNIwM2jQIKxfvx5z5szB/PnzER4ejiVLluCBBx4wnzNr1ixUVlZi6tSpKCoqQkxMDNLT06FSqSSsvG3jithERORIZEIIIXUR9lRaWgq1Wo2SkhKOn7GBjJyzeOzj7XCRy/DNtJu5kCQREdmFNd/fki9nQM6jtKoaL3y9DwBXxCYiIsdhVTeTEAKZmZn4+eefcfz4cVRUVCAgIAD9+vXDiBEjOKdLK7do0584W6pHGFfEJiIiB9KklpnKykqkpKQgJCQEI0eOxH/+8x8UFxfDxcUFR44cwcsvv4zw8HCMGjUK27Zts3fNJIH6K2KncEVsIiJyIE1qmenSpQtiYmKwfPly3H777XBza7j2zokTJ7BmzRrcd999eOGFF/DYY4/ZvFiSBlfEJiIiR9akAcB//PEHoqOjm3RBg8GAEydOICoq6oaLswUOAL5x//j+IJZtOYIAlRKbZ8ZxIUkiIrI7mw8AbmqQAQCFQuEwQYZuHFfEJiIiR9fseWZqamrw7rvv4qeffoLRaMTNN9+MadOmwd2d6/O0FlwRm4iInEGzw8z06dNx6NAhjBs3DtXV1fj444+xfft2fPbZZ7asjyRUf0Xs+VwRm4iIHFSTw8z69evx17/+1fw6PT0dBw8ehItL7VMtt99+OwYPHmz7CkkSV66IHcgVsYmIyEE1edK8Dz/8EGPHjsXp06cBAP3798eUKVPw3Xff4dtvv8WsWbMwaNAguxVKLYcrYhMRkTNpcpjZuHEjxo8fj/j4eLz11lt477334OPjg7lz5+LFF19ESEgI1qxZY89aqYVwRWwiInImVq/NVFxcjGeffRZ79+7Fu+++i759+9qpNNvgo9nWOafTY8TiTJRUVmP2yG6YEhcpdUlERNQG2XVtpnbt2uH999/H66+/jgcffBDPPvssKisrm10sORauiE1ERM6myWEmLy8P9913H3r16oUHHngAUVFR2LFjBzw8PNC3b19s2rTJnnVSC8jIOYv/7M2Hi1yGRXf1hqsL1yElIiLH1+Rvq4ceeggymQyvv/46AgMDMXnyZCgUCsyfPx9ff/01UlNTce+999qzVrKj+itiP3ZLBFfEJiIip9HkR7O3b9+O3bt3IzIyErfffjvCwy93QXTv3h1bt27Fe++9Z5ciyf7qr4idPIIzOBMRkfNocpjp378/XnrpJUycOBGbN29Gr169Gpzz+OOP27Q4ahlcEZuIiJxZk7uZPv74Y+j1ejz11FM4ffo03n33XXvWRS2EK2ITEZGza3LLTGhoKL744gt71kIS2LDnDI6dL0eASok5o7pLXQ4REZHVmtQyU15ebtVFrT2fpPO/I+cB1LbKcEVsIiJyRk0KM507d0ZKSgrOnDlz1XOEEMjIyMDIkSOxdOlSmxVI9iOEQNbRCwCAIZHtJa6GiIioeZrUzfTTTz/hhRdewCuvvIK+ffti4MCBCA4Ohru7O4qKipCTk4Nff/0Vbm5umDNnDgcCO4mj58pwTqeHwlWO/p18pS6HiIioWZoUZrp27YrPP/8cp06dwueff46tW7ciKysLlZWV8Pf3R79+/fD+++9j1KhRkMs50ZqzqGuVGRjqyyeYiIjIaTV5ADAAdOzYEU899RSeeuope9VDLSjrSG2YiWUXExEROTE2o7RRJpPAr8fqxsvwcWwiInJeDDNtVE5+KUoqq+GlcEHvjly6gIiInBfDTBv166XxMjeF+8GNC0oSEZET47dYG5V1tHZ+Gc74S0REzo5hpg2qNprwe+5FAJxfhoiInJ/VYSYsLAzz58/HyZMn7VEPtYC9p0pQbjBC7eGGHkE+UpdDRER0Q6wOM08//TS++eYbREREICEhAWvXroVer7dHbWQnv17qYhoS0R5yuUziaoiIiG6M1WHmySefxI4dO7Bjxw706NED06dPR1BQEJ544gns3LnTqmvNmzcPMpnMYtNqtebjQgjMmzcPwcHB8PDwQHx8PPbv329tyXSFusnyYjuzi4mIiJxfs8fM9OnTB2+++SZOnz6Nl19+GR988AEGDRqEPn364KOPPoIQoknX6dmzJ/Lz883bvn37zMfS0tKwePFiLFu2DNnZ2dBqtUhISIBOp2tu2W1eVbUR208UAeBkeURE1DpYNQNwfdXV1Vi/fj1WrFiBjIwMDB48GH/7299w5swZzJ07F5s3b8aaNWuuX4Crq0VrTB0hBJYsWYK5c+di3LhxAIBVq1ZBo9FgzZo1mDx5cnNLb9N2niyCocaEAJUSkQHeUpdDRER0w6wOMzt37sSKFSvw2WefwcXFBQ8++CD++c9/olu3buZzEhMTMWzYsCZd7/DhwwgODoZSqURMTAxSUlIQERGB3NxcFBQUIDEx0XyuUqlEXFwcsrKyrhpm9Hq9xRie0tJSa3/EVm3b0ctLGMhkHC9DRETOz+pupkGDBuHw4cN45513cOrUKfzjH/+wCDIA0KNHD4wfP/6614qJicHHH3+M77//Hu+//z4KCgoQGxuLCxcuoKCgAACg0Wgs3qPRaMzHGpOamgq1Wm3eQkJCrP0RW7Wso1yPiYiIWherW2aOHTuG0NDQa57j5eWFFStWXPdaI0eONP+5V69eGDJkCCIjI7Fq1SoMHjwYABq0HgghrtmiMGfOHMycOdP8urS0lIHmknJ9DXbnFQPgZHlERNR6WN0yU1hYiN9++63B/t9++w3bt2+/oWK8vLzQq1cvHD582DyO5spWmMLCwgatNfUplUr4+PhYbFQr+/hF1JgEOvp6IMTPU+pyiIiIbMLqMDNt2jTk5eU12H/69GlMmzbthorR6/U4cOAAgoKCEB4eDq1Wi4yMDPNxg8GAzMxMxMbG3tDntFW/souJiIhaIau7mXJyctC/f/8G+/v164ecnByrrvXMM8/gjjvuQKdOnVBYWIjXXnsNpaWlmDhxImQyGZKTk5GSkoKoqChERUUhJSUFnp6emDBhgrVlE+qPl2EXExERtR5WhxmlUomzZ88iIiLCYn9+fj5cXa273KlTp3D//ffj/PnzCAgIwODBg7Ft2zbzmJxZs2ahsrISU6dORVFREWJiYpCeng6VSmVt2W1eSUU1/jhTAoDrMRERUesiE02d3e6S8ePHo6CgAN988w3UajUAoLi4GGPHjkVgYCD+/e9/26XQ5iotLYVarUZJSUmbHj/z/f4CTF69A5EBXvjh6XipyyEiIroma76/rW6ZeeONNzBs2DCEhoaiX79+AIDdu3dDo9Fg9erVzauY7O5XdjEREVErZXWY6dChA/bu3YtPP/0Ue/bsgYeHBx555BHcf//9cHNzs0eNZANZlxaX5OBfIiJqbZq1nIGXlxcef/xxW9dCdnJOp8ehs2UAgMERDDNERNS6NHttppycHJw8eRIGg8Fi/5133nnDRZFt/XqstoupR5APfL0UEldDRERkW82aAfivf/0r9u3bB5lMZl4du25WXqPRaNsK6Yb9yi4mIiJqxayeNG/GjBkIDw/H2bNn4enpif3792Pr1q0YOHAgfvrpJzuUSDfKPL9MZ4YZIiJqfaxumfn111/x448/IiAgAHK5HHK5HEOHDkVqaiqmT5+OXbt22aNOaqZTRRU4caECLnIZBoX5SV0OERGRzVndMmM0GuHt7Q0A8Pf3x5kzZwAAoaGhOHjwoG2roxtW90h2745qqNz5tBkREbU+VrfMREdHY+/evYiIiEBMTAzS0tKgUCjw3nvvNZgVmKTH9ZiIiKi1szrMvPDCCygvLwcAvPbaa0hKSsItt9yC9u3bY926dTYvkJpPCMH1mIiIqNWzOszcfvvt5j9HREQgJycHFy9ehK+vr/mJJnIMuefLUVBaBYWLHANCfaUuh4iIyC6sGjNTU1MDV1dX/PHHHxb7/fz8GGQcUF2rTP/QdnB3c5G4GiIiIvuwKsy4uroiNDSUc8k4Ca7HREREbYHVTzO98MILmDNnDi5evGiPeshGTCZhnvmXg3+JiKg1s3rMzNKlS3HkyBEEBwcjNDQUXl5eFsd37txps+Ko+Q6e1eFiuQGeChf07thO6nKIiIjsxuowM3bsWDuUQbZWN15mUJgfFK5WN8ARERE5DavDzMsvv2yPOsjGuB4TERG1Ffxf9laoxmjCb8dqxzRx8C8REbV2VrfMyOXyaz6GzSedpPfHmVLo9DXwcXdFj2AfqcshIiKyK6vDzPr16y1eV1dXY9euXVi1ahVeeeUVmxVGzZd1qYtpcER7uMg5/w8REbVuVoeZMWPGNNh39913o2fPnli3bh3+9re/2aQwaj6ux0RERG2JzcbMxMTEYPPmzba6HDWTvsaI7OOXxst05ngZIiJq/WwSZiorK/HWW2+hY8eOtrgc3YDdJ4tRVW2Cv7cCUYHeUpdDRERkd1Z3M125oKQQAjqdDp6envjkk09sWhxZr25+mSGR/lwvi4iI2gSrw8w///lPiy9JuVyOgIAAxMTEwNeXKzNLjeNliIiorbE6zDz88MN2KINsocJQg115RQAYZoiIqO2weszMihUr8PnnnzfY//nnn2PVqlU2KYqaZ/vxIlQbBTq080AnP0+pyyEiImoRVoeZhQsXwt+/4VMygYGBSElJsUlR1DyXx8u053gZIiJqM6wOMydOnEB4eHiD/aGhoTh58qRNiqLm4XpMRETUFlkdZgIDA7F3794G+/fs2YP27fklKpWSymrsO10CoLZlhoiIqK2wOsyMHz8e06dPx5YtW2A0GmE0GvHjjz9ixowZGD9+fLMLSU1NhUwmQ3JysnmfEALz5s1DcHAwPDw8EB8fj/379zf7M1qz33MvwiSACH8vBKk9pC6HiIioxVgdZl577TXExMTgtttug4eHBzw8PJCYmIjhw4c3e8xMdnY23nvvPfTu3dtif1paGhYvXoxly5YhOzsbWq0WCQkJ0Ol0zfqc1qxuPSa2yhARUVtjdZhRKBRYt24dDh48iE8//RRfffUVjh49io8++ggKhcLqAsrKyvDAAw/g/ffft5inRgiBJUuWYO7cuRg3bhyio6OxatUqVFRUYM2aNVZ/Tmt3eX4ZLmFARERtS7OXM4iKisI999yDpKQkhIaGNruAadOmYfTo0RgxYoTF/tzcXBQUFCAxMdG8T6lUIi4uDllZWc3+vNbofJkefxbUtlYNjvCTuBoiIqKWZXWYufvuu7Fw4cIG+19//XXcc889Vl1r7dq12LlzJ1JTUxscKygoAABoNBqL/RqNxnysMXq9HqWlpRZba7ftWG2rTDetCu29lRJXQ0RE1LKsDjOZmZkYPXp0g/1/+ctfsHXr1iZfJy8vDzNmzMAnn3wCd3f3q5535XwpQohrzqGSmpoKtVpt3kJCQppck7PKYhcTERG1YVaHmbKyskbHxri5uVnVCrJjxw4UFhZiwIABcHV1haurKzIzM7F06VK4urqaW2SubIUpLCxs0FpT35w5c1BSUmLe8vLymlyTs+J6TERE1JZZHWaio6Oxbt26BvvXrl2LHj16NPk6t912G/bt24fdu3ebt4EDB+KBBx7A7t27ERERAa1Wi4yMDPN7DAYDMjMzERsbe9XrKpVK+Pj4WGyt2ZniSuSeL4dcBtzE8TJERNQGWb3Q5Isvvoi77roLR48exfDhwwEAP/zwAz777LNG12y6GpVKhejoaIt9Xl5eaN++vXl/cnIyUlJSEBUVhaioKKSkpMDT0xMTJkywtuxWq65VplfHdvBxd5O4GiIiopZndZi588478fXXXyMlJQVffPEFPDw80Lt3b2zevBlxcXE2LW7WrFmorKzE1KlTUVRUhJiYGKSnp0OlUtn0c5xZFruYiIiojZMJIYStLrZ792707dvXVpezidLSUqjVapSUlLS6LichBG5e+CPOlFRh9d9uwi1RAVKXREREZBPWfH83e56ZOiUlJfjXv/6F/v37Y8CAATd6ObLCiQsVOFNSBTcXGQaGcrwMERG1Tc0OMz/++CMeeOABBAUF4a233sKoUaOwfft2W9ZG11HXxdSvky88FC4SV0NERCQNq8bMnDp1CitXrsRHH32E8vJy3HvvvaiursaXX35p1ZNMZBt16zFxvAwREbVlTW6ZGTVqFHr06IGcnBy89dZbOHPmDN566y171kbXIITgekxERESwomUmPT0d06dPx9///ndERUXZsyZqgkNny3Ch3AB3Nzn6hrSTuhwiIiLJNLll5ueff4ZOp8PAgQMRExODZcuW4dy5c/asja6hrotpUJgfFK43PI6biIjIaTX5W3DIkCF4//33kZ+fj8mTJ2Pt2rXo0KEDTCYTMjIyoNPp7FknXYHrMREREdWy+n/pPT09MWnSJPzyyy/Yt28fnn76aSxcuBCBgYG488477VEjXcFoEuaVsjn4l4iI2rob6p/o2rUr0tLScOrUKXz22We2qomuY/+ZEuiqaqByd0XP4NY1ESAREZG1bDLYwsXFBWPHjsWGDRtscTm6jrouppjw9nB14XgZIiJq2/hN6IS4HhMREdFlDDNOxlBjQnbuRQBAbGeGGSIiIoYZJ7PnVDEqq41o76VAl0CuHk5ERMQw42SyjtR2MQ2ObA+5XCZxNURERNJjmHEyXI+JiIjIEsOME6k0GLHrZDEATpZHRERUh2HGiew4UQSD0YQgtTvC2ntKXQ4REZFDYJhxInVdTEMi20Mm43gZIiIigGHGqXA9JiIiooYYZpxEaVU19p4qBlDbMkNERES1GGacRHbuRZgEENbeEx3aeUhdDhERkcNgmHESdV1MQ9jFREREZIFhxklwPSYiIqLGMcw4gYvlBhzILwUADI5gmCEiIqqPYcYJbDtW2yrTVaNCgEopcTVERESOhWHGCdSfX4aIiIgsMcw4AY6XISIiujqGGQdXUFKFY+fKIZcBMRwvQ0RE1ADDjIP79VhtF1N0BzXUHm4SV0NEROR4GGYcXNaRuvll2CpDRETUGIYZByaE4HpMRERE1yFpmHnnnXfQu3dv+Pj4wMfHB0OGDMGmTZvMx4UQmDdvHoKDg+Hh4YH4+Hjs379fwopbVt7FSpwuroSrXIZBYb5Sl0NEROSQJA0zHTt2xMKFC7F9+3Zs374dw4cPx5gxY8yBJS0tDYsXL8ayZcuQnZ0NrVaLhIQE6HQ6KctuMXWPZPfr1A6eCleJqyEiInJMkoaZO+64A6NGjUKXLl3QpUsXLFiwAN7e3ti2bRuEEFiyZAnmzp2LcePGITo6GqtWrUJFRQXWrFkjZdkthusxERERXZ/DjJkxGo1Yu3YtysvLMWTIEOTm5qKgoACJiYnmc5RKJeLi4pCVlXXV6+j1epSWllpszshyvAwH/xIREV2N5GFm37598Pb2hlKpxJQpU7B+/Xr06NEDBQUFAACNRmNxvkajMR9rTGpqKtRqtXkLCQmxa/32cqSwDOfL9FC6ytGvUzupyyEiInJYkoeZrl27Yvfu3di2bRv+/ve/Y+LEicjJyTEfl8lkFucLIRrsq2/OnDkoKSkxb3l5eXar3Z7qWmUGhflB6eoicTVERESOS/JRpQqFAp07dwYADBw4ENnZ2XjzzTfx3HPPAQAKCgoQFBRkPr+wsLBBa019SqUSSqXzL8bI9ZiIiIiaRvKWmSsJIaDX6xEeHg6tVouMjAzzMYPBgMzMTMTGxkpYof0ZTQLbjl0EwPEyRERE1yNpy8zzzz+PkSNHIiQkBDqdDmvXrsVPP/2E7777DjKZDMnJyUhJSUFUVBSioqKQkpICT09PTJgwQcqy7e5AfilKKqvhrXRFrw5qqcshIiJyaJKGmbNnz+LBBx9Efn4+1Go1evfuje+++w4JCQkAgFmzZqGyshJTp05FUVERYmJikJ6eDpVKJWXZdlfXxRQT7gdXF4drPCMiInIoMiGEkLoIeyotLYVarUZJSQl8fHykLqdJHl7xO346eA4vjO6OR2+JkLocIiKiFmfN9zf/t9/BVBtN+D23brwMJ8sjIiK6HoYZB7P3VDEqDEb4erqhm7Z1d6cRERHZAsOMg8k6UreEQXvI5VefT4eIiIhqMcw4GK7HREREZB2GGQdSVW3EjpNFADi/DBERUVMxzDiQnSeKYKgxQeOjRIS/l9TlEBEROQWGGQdyeZVs/2uuP0VERESXMcw4EK7HREREZD2GGQdRpq/BnlMlADhehoiIyBoMMw4iO/cijCaBTn6e6OjrKXU5REREToNhxkHUdTGxVYaIiMg6DDMO4vL8MgwzRERE1mCYcQBF5Qbk5JcCYJghIiKyFsOMA/gt9wKEAKICvRGocpe6HCIiIqfCMOMALs8vw1YZIiIiazHMOACux0RERNR8DDMSKyytwpHCMshkwOAIP6nLISIicjoMMxL79Vhtq0zPYB+081RIXA0REZHzYZiRWNaRy+sxERERkfUYZiSWdYzrMREREd0IhhkJ5V2sQN7FSrjKZRgUxvEyREREzcEwI6FfLz3F1CekHbyVrhJXQ0RE5JwYZiTE9ZiIiIhuHMOMRIQQXI+JiIjIBhhmJHL0XDkKdXooXOXo38lX6nKIiIicFsOMRH691MU0MNQX7m4uEldDRETkvBhmJML1mIiIiGyDYUYCJpMwz/zL9ZiIiIhuDMOMBA4UlKK4ohpeChf07qiWuhwiIiKnxjAjgbr5ZW4K94ObC28BERHRjeA3qQQuj5dhFxMREdGNkjTMpKamYtCgQVCpVAgMDMTYsWNx8OBBi3OEEJg3bx6Cg4Ph4eGB+Ph47N+/X6KKb1y10YTfjnF+GSIiIluRNMxkZmZi2rRp2LZtGzIyMlBTU4PExESUl5ebz0lLS8PixYuxbNkyZGdnQ6vVIiEhATqdTsLKm2/f6RKUG4xQe7ihR5CP1OUQERE5PUkXBPruu+8sXq9YsQKBgYHYsWMHhg0bBiEElixZgrlz52LcuHEAgFWrVkGj0WDNmjWYPHmyFGXfkLrxMkMi2kMul0lcDRERkfNzqDEzJSUlAAA/v9oVpHNzc1FQUIDExETzOUqlEnFxccjKymr0Gnq9HqWlpRabIzGvx9SZXUxERES24DBhRgiBmTNnYujQoYiOjgYAFBQUAAA0Go3FuRqNxnzsSqmpqVCr1eYtJCTEvoVboaraiO3HiwBwsjwiIiJbcZgw88QTT2Dv3r347LPPGhyTySy7Y4QQDfbVmTNnDkpKSsxbXl6eXeptjl0ni6GvMSFApURkgLfU5RAREbUKko6ZqfPkk09iw4YN2Lp1Kzp27Gjer9VqAdS20AQFBZn3FxYWNmitqaNUKqFUKu1bcDPVrccUG9n+qmGMiIiIrCNpy4wQAk888QS++uor/PjjjwgPD7c4Hh4eDq1Wi4yMDPM+g8GAzMxMxMbGtnS5N4zrMREREdmepC0z06ZNw5o1a/DNN99ApVKZx8Go1Wp4eHhAJpMhOTkZKSkpiIqKQlRUFFJSUuDp6YkJEyZIWbrVyvU12J1XDICT5REREdmSpGHmnXfeAQDEx8db7F+xYgUefvhhAMCsWbNQWVmJqVOnoqioCDExMUhPT4dKpWrham9M9vGLqDEJdPT1QIifp9TlEBERtRqShhkhxHXPkclkmDdvHubNm2f/guzoV3YxERER2YXDPM3U2nE9JiIiIvtgmGkBJRXV2H+mdkJArsdERERkWwwzLeC33AswCSAywAsaH3epyyEiImpVGGZaALuYiIiI7IdhpgVw8C8REZH9MMzY2TmdHgfP6gAAgyMYZoiIiGyNYcbOth2rbZXpEeQDXy+FxNUQERG1PgwzdsYlDIiIiOyLYcbOzItLdmaYISIisgeGGTs6XVyJ4xcq4CKXYVCYn9TlEBERtUoMM3ZU9xRT745qqNzdJK6GiIiodWKYsaOsui4mjpchIiKyG4YZOxFC1JtfhpPlERER2QvDjJ0cv1CB/JIqKFzkGBDqK3U5RERErRbDjJ3UdTH1D20HdzcXiashIiJqvRhm7ITrMREREbUMhhk7MJkEtnGyPCIiohbBMGMHhwp1uFBugKfCBb07tpO6HCIiolaNYcYOso7UtsoMCvODwpW/YiIiInviN60dcD0mIiKilsMwY2M1RhN+O8bBv0RERC2FYcbG9p8phU5fAx93V/QI9pG6HCIiolaPYcbG6rqYBke0h4tcJnE1RERErR/DjI1xPSYiIqKWxTBjQ4YaE7KPXwQAxHbmeBkiIqKWwDBjQ7vzilFVbYK/twJRgd5Sl0NERNQmMMzYUF0X05BIf8hkHC9DRETUEhhmbIjzyxAREbU8hhkbqTQYsetkEQCGGSIiopbEMGMj209cRLVRoEM7D3Ty85S6HCIiojaDYcZG6rqYhkS253gZIiKiFiRpmNm6dSvuuOMOBAcHQyaT4euvv7Y4LoTAvHnzEBwcDA8PD8THx2P//v3SFHsdHC9DREQkDUnDTHl5Ofr06YNly5Y1ejwtLQ2LFy/GsmXLkJ2dDa1Wi4SEBOh0uhau9NpKq6qx71QxgNqWGSIiImo5rlJ++MiRIzFy5MhGjwkhsGTJEsydOxfjxo0DAKxatQoajQZr1qzB5MmTW7LUa/r92EWYBBDh74UgtYfU5RAREbUpDjtmJjc3FwUFBUhMTDTvUyqViIuLQ1ZW1lXfp9frUVpaarHZW/3xMkRERNSyHDbMFBQUAAA0Go3Ffo1GYz7WmNTUVKjVavMWEhJi1zqB+usxcQkDIiKiluawYabOlU8GCSGu+bTQnDlzUFJSYt7y8vLsWt+FMj3+LKgdwzM4ws+un0VEREQNSTpm5lq0Wi2A2haaoKAg8/7CwsIGrTX1KZVKKJVKu9dXZ9ux2oUlu2lVaO/dcp9LREREtRy2ZSY8PBxarRYZGRnmfQaDAZmZmYiNjZWwMkvsYiIiIpKWpC0zZWVlOHLkiPl1bm4udu/eDT8/P3Tq1AnJyclISUlBVFQUoqKikJKSAk9PT0yYMEHCqi39yvlliIiIJCVpmNm+fTtuvfVW8+uZM2cCACZOnIiVK1di1qxZqKysxNSpU1FUVISYmBikp6dDpVJJVbKF/JJKHDtfDrkMuInjZYiIiCQhE0IIqYuwp9LSUqjVapSUlMDHx8em1/5q5ynM/Pce9Alph2+m3WzTaxMREbVl1nx/O+yYGWfAJQyIiIikxzDTTEIIjpchIiJyAAwzzXTyYgVOF1fCzUWGgaEcL0NERCQVhplmquti6tfJFx4KF4mrISIiarsYZprpYrkB7m5ydjERERFJjE8z3QBDjQn6GiNU7m42vS4REVFbZ833t8MuZ+AMFK5yKFzZuEVERCQlfhMTERGRU2OYISIiIqfGMENEREROjWGGiIiInBrDDBERETk1hhkiIiJyagwzRERE5NQYZoiIiMipMcwQERGRU2OYISIiIqfGMENEREROjWGGiIiInBrDDBERETm1Vr9qthACQO1S4kREROQc6r63677Hr6XVhxmdTgcACAkJkbgSIiIispZOp4Narb7mOTLRlMjjxEwmE86cOQOVSgWZTGbTa5eWliIkJAR5eXnw8fGx6bXJerwfjoX3w7HwfjgW3o/rE0JAp9MhODgYcvm1R8W0+pYZuVyOjh072vUzfHx8+C+jA+H9cCy8H46F98Ox8H5c2/VaZOpwADARERE5NYYZIiIicmoMMzdAqVTi5ZdfhlKplLoUAu+Ho+H9cCy8H46F98O2Wv0AYCIiImrd2DJDRERETo1hhoiIiJwawwwRERE5NYYZIiIicmoMM830r3/9C+Hh4XB3d8eAAQPw888/S11Sq7R161bccccdCA4Ohkwmw9dff21xXAiBefPmITg4GB4eHoiPj8f+/fstztHr9XjyySfh7+8PLy8v3HnnnTh16lQL/hStR2pqKgYNGgSVSoXAwECMHTsWBw8etDiH96TlvPPOO+jdu7d54rUhQ4Zg06ZN5uO8F9JKTU2FTCZDcnKyeR/viX0wzDTDunXrkJycjLlz52LXrl245ZZbMHLkSJw8eVLq0lqd8vJy9OnTB8uWLWv0eFpaGhYvXoxly5YhOzsbWq0WCQkJ5jW5ACA5ORnr16/H2rVr8csvv6CsrAxJSUkwGo0t9WO0GpmZmZg2bRq2bduGjIwM1NTUIDExEeXl5eZzeE9aTseOHbFw4UJs374d27dvx/DhwzFmzBjzlyPvhXSys7Px3nvvoXfv3hb7eU/sRJDVbrrpJjFlyhSLfd26dROzZ8+WqKK2AYBYv369+bXJZBJarVYsXLjQvK+qqkqo1WqxfPlyIYQQxcXFws3NTaxdu9Z8zunTp4VcLhffffddi9XeWhUWFgoAIjMzUwjBe+IIfH19xQcffMB7ISGdTieioqJERkaGiIuLEzNmzBBC8L8Pe2LLjJUMBgN27NiBxMREi/2JiYnIysqSqKq2KTc3FwUFBRb3QqlUIi4uznwvduzYgerqaotzgoODER0dzftlAyUlJQAAPz8/ALwnUjIajVi7di3Ky8sxZMgQ3gsJTZs2DaNHj8aIESMs9vOe2E+rX2jS1s6fPw+j0QiNRmOxX6PRoKCgQKKq2qa633dj9+LEiRPmcxQKBXx9fRucw/t1Y4QQmDlzJoYOHYro6GgAvCdS2LdvH4YMGYKqqip4e3tj/fr16NGjh/mLj/eiZa1duxY7d+5EdnZ2g2P878N+GGaaSSaTWbwWQjTYRy2jOfeC9+vGPfHEE9i7dy9++eWXBsd4T1pO165dsXv3bhQXF+PLL7/ExIkTkZmZaT7Oe9Fy8vLyMGPGDKSnp8Pd3f2q5/Ge2B67mazk7+8PFxeXBgm5sLCwQdom+9JqtQBwzXuh1WphMBhQVFR01XPIek8++SQ2bNiALVu2oGPHjub9vCctT6FQoHPnzhg4cCBSU1PRp08fvPnmm7wXEtixYwcKCwsxYMAAuLq6wtXVFZmZmVi6dClcXV3Nv1PeE9tjmLGSQqHAgAEDkJGRYbE/IyMDsbGxElXVNoWHh0Or1VrcC4PBgMzMTPO9GDBgANzc3CzOyc/Pxx9//MH71QxCCDzxxBP46quv8OOPPyI8PNziOO+J9IQQ0Ov1vBcSuO2227Bv3z7s3r3bvA0cOBAPPPAAdu/ejYiICN4Te5Fm3LFzW7t2rXBzcxMffvihyMnJEcnJycLLy0scP35c6tJaHZ1OJ3bt2iV27dolAIjFixeLXbt2iRMnTgghhFi4cKFQq9Xiq6++Evv27RP333+/CAoKEqWlpeZrTJkyRXTs2FFs3rxZ7Ny5UwwfPlz06dNH1NTUSPVjOa2///3vQq1Wi59++knk5+ebt4qKCvM5vCctZ86cOWLr1q0iNzdX7N27Vzz//PNCLpeL9PR0IQTvhSOo/zSTELwn9sIw00xvv/22CA0NFQqFQvTv39/8aCrZ1pYtWwSABtvEiROFELWPOr788stCq9UKpVIphg0bJvbt22dxjcrKSvHEE08IPz8/4eHhIZKSksTJkycl+GmcX2P3AoBYsWKF+Rzek5YzadIk899DAQEB4rbbbjMHGSF4LxzBlWGG98Q+ZEIIIU2bEBEREdGN45gZIiIicmoMM0REROTUGGaIiIjIqTHMEBERkVNjmCEiIiKnxjBDRERETo1hhoiIiJwawwwRtXphYWFYsmSJ1GUQkZ0wzBCRTT388MMYO3YsACA+Ph7Jyckt9tkrV65Eu3btGuzPzs7G448/3mJ1EFHLcpW6ACKi6zEYDFAoFM1+f0BAgA2rISJHw5YZIrKLhx9+GJmZmXjzzTchk8kgk8lw/PhxAEBOTg5GjRoFb29vaDQaPPjggzh//rz5vfHx8XjiiScwc+ZM+Pv7IyEhAQCwePFi9OrVC15eXggJCcHUqVNRVlYGAPjpp5/wyCOPoKSkxPx58+bNA9Cwm+nkyZMYM2YMvL294ePjg3vvvRdnz541H583bx769u2L1atXIywsDGq1GuPHj4dOp7PvL42ImoVhhojs4s0338SQIUPw2GOPIT8/H/n5+QgJCUF+fj7i4uLQt29fbN++Hd999x3Onj2Le++91+L9q1atgqurK/73v//h3XffBQDI5XIsXboUf/zxB1atWoUff/wRs2bNAgDExsZiyZIl8PHxMX/eM88806AuIQTGjh2LixcvIjMzExkZGTh69Cjuu+8+i/OOHj2Kr7/+Ghs3bsTGjRuRmZmJhQsX2um3RUQ3gt1MRGQXarUaCoUCnp6e0Gq15v3vvPMO+vfvj5SUFPO+jz76CCEhITh06BC6dOkCAOjcuTPS0tIsrll//E14eDheffVV/P3vf8e//vUvKBQKqNVqyGQyi8+70ubNm7F3717k5uYiJCQEALB69Wr07NkT2dnZGDRoEADAZDJh5cqVUKlUAIAHH3wQP/zwAxYsWHBjvxgisjm2zBBRi9qxYwe2bNkCb29v89atWzcAta0hdQYOHNjgvVu2bEFCQgI6dOgAlUqFhx56CBcuXEB5eXmTP//AgQMICQkxBxkA6NGjB9q1a4cDBw6Y94WFhZmDDAAEBQWhsLDQqp+ViFoGW2aIqEWZTCbccccdWLRoUYNjQUFB5j97eXlZHDtx4gRGjRqFKVOm4NVXX4Wfnx9++eUX/O1vf0N1dXWTP18IAZlMdt39bm5uFsdlMhlMJlOTP4eIWg7DDBHZjUKhgNFotNjXv39/fPnllwgLC4Ora9P/Ctq+fTtqamrwxhtvQC6vbVT+97//fd3Pu1KPHj1w8uRJ5OXlmVtncnJyUFJSgu7duze5HiJyHOxmIiK7CQsLw2+//Ybjx4/j/PnzMJlMmDZtGi5evIj7778fv//+O44dO4b09HRMmjTpmkEkMjISNTU1eOutt3Ds2DGsXr0ay5cvb/B5ZWVl+OGHH3D+/HlUVFQ0uM6IESPQu3dvPPDAA9i5cyd+//13PPTQQ4iLi2u0a4uIHB/DDBHZzTPPPAMXFxf06NEDAQEBOHnyJIKDg/G///0PRqMRt99+O6KjozFjxgyo1Wpzi0tj+vbti8WLF2PRokWIjo7Gp59+itTUVItzYmNjMWXKFNx3330ICAhoMIAYqO0u+vrrr+Hr64thw4ZhxIgRiIiIwLp162z+8xNRy5AJIYTURRARERE1F1tmiIiIyKkxzBAREZFTY5ghIiIip8YwQ0RERE6NYYaIiIicGsMMEREROTWGGSIiInJqDDNERETk1BhmiIiIyKkxzBAREZFTY5ghIiIip8YwQ0RERE7t/wExf/YBn+VpLgAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the network's performance\n",
    "visualizer = Visualizer(network)\n",
    "visualizer.display_predictions(10, display_correct=True)\n",
    "visualizer.display_predictions(10, display_correct=False)\n",
    "visualizer.graph_accuracy()\n",
    "visualizer.graph_cost()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T06:39:44.994655Z",
     "start_time": "2023-06-07T06:39:41.903494Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "# **Clarifications**\n",
    "Although not necessary, I believe some topics needed some further explanation. I've included those in this section.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Derivative Vs. Gradient**\n",
    "These two terms are used everywhere in machine learning. People use them interchangeably (including myself) without any issues, but there technically is a difference.\n",
    "\n",
    "**Derivative**\n",
    "Measures how a function changes as its inputs change. The derivative of a loss function with respect to a parameter provides information about the sensitivity of the cost to changes in the parameters. It's useful when you have only one parameter to optimize.\n",
    "\n",
    "**Gradient**\n",
    "A generalization of the derivative concept function with more than one input. It's a vector that points in the direction of steepest ascent of the loss function, with its magnitude representing the rate of increase in that direction. When we compute gradient descent, we find the gradient and move in the opposite direction (the steepest descent). Gradient is computed by taking the partial derivatives of the loss function with respect to all the parameters.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"Images/Gradient.jpeg\" alt=\"Gradient\" width=\"1200\">\n",
    "\n",
    "Image source: statisticshowto.com\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Loss Function**\n",
    "When training a neural network, we don't compute the cost at each step. Furthermore, our code actually doesn't even explicitly calculate the cost at all; it only calculates the derivatives of the loss function with respect to the model's parameters. While we may not explicitly calculate the cost itself, we do calculate something directly derived from the loss function. Therefore, you could say we implicitly calculate the cost.\n",
    "\n",
    "Although factored out in our calculation of cost, the incorrect classes are, in fact, part of the backpropagation calculation and contribute to the gradient descent calculations. Ideally, the model shouldn't have given any probability to the incorrect classes. However, because it's learning, it did, and it needs to be corrected by adjusting the weights and biases. When training a multi-class classifier, the goal is not only to get the correct class right, but also to get the incorrect classes wrong. This ensures that the model is penalized more for making incorrect predictions, and less for making correct predictions.\n",
    "\n",
    "If the model predicts a high probability for the correct class (closer to 1), the difference will be small, leading to a smaller gradient and a smaller update to the parameters. Since the model is making correct predictions, we don't want to adjust the weights too much. If the model predicts a low probability for the correct class or a high probability for an incorrect class, the difference will be large, leading to a larger gradient and a larger update to the parameters. Since the model is making incorrect predictions, we want to change the parameters more to correct these errors.\n",
    "\n",
    "If the model's predicted probability for the correct class increases (i.e. the model is predicting more accurately), then $dZ^{[2]}$ for that class gets smaller (closer to 0) because $dZ^{[2]} = \\text{predicted probability} - 1$ Therefore, $dW^{[2]}$ also gets smaller, since it's directly computed using $dZ^{[2]}$. Conversely, if the model's predicted probability for the correct class decreases, then $dZ^{[2]}$ for that class gets larger (closer to 1). As a result, $dW^{[2]}$ gets larger too. To reinforce this, let's consider an example using the same variables in our code. Assume that we have a neural network with 3 classes, and the outputs from the hidden layer ($A^{[1]}$) and the output layer ($A^{[2]}$) are as follows:\n",
    "$${A^{[1]} = [0.6, 0.4]}$$\n",
    "$$A^{[2]} = [0.1, 0.2, 0.7]$$\n",
    "\n",
    "Let's also say that the true label is Class 3, so the one-hot encoded labels ($\\text{one_hot_Y}$) would be:\n",
    "$$\\text{one_hot_Y} = [0, 0, 1]$$\n",
    "\n",
    "Now, we calculate $dZ2$:\n",
    "$$dZ^{[2]} = A^{[2]} - \\text{one_hot_Y}$$\n",
    "$$= [0.1, 0.2, -0.3]$$\n",
    "\n",
    "$dZ^{[2]}$ is used to calculate $dW^{[2]}$ in the formula $dW^{[2]} = dZ^{[2]} \\cdot A^{[1]T} / m$ during backpropagation. If we have one training example (so $m=1$), this formula simplifies to $dW^{[2]} = dZ^{[2]} \\cdot A^{[1]T}$.\n",
    "\n",
    "Let's calculate $dW^{[2]}$ using the dot product:\n",
    "$$dW^{[2]} = dZ^{[2]} \\cdot A^{[1]T} = [(0.1 \\cdot 0.6 + 0.1 \\cdot 0.4), (0.2 \\cdot 0.6 + 0.2 \\cdot 0.4), (-0.3 \\cdot 0.6 - 0.3 \\cdot 0.4)]$$\n",
    "$$= [0.06, 0.12, -0.18]$$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Overestimation and Underestimation**\n",
    "If the predicted probability of a class in $A^{[2]}$ is higher than the actual label, we can say the model overestimates that class. In our example, the model predicted 0.1 for Class 1 and 0.2 for Class 2, but the actual labels for these classes are 0. Therefore, the model overestimated the probabilities of Class 1 and Class 2. $dW^{[2]}$ will also be high, indicating that we need to push the weights in the direction that reduces the cost. Overestimating can lead to incorrect decisions. For example, in a medical diagnosis algorithm, if the model overestimates the correct class (e.g., predicts a disease that a patient does not have), it may lead to unnecessary medical treatments.\n",
    "\n",
    "Overestimating can reduce the discriminative power of the model. When the predicted probability for the correct class is too high, it means the model is assigning high confidence to that class. This may result in the model becoming less sensitive to subtle differences between the correct class and other similar classes. This loss of sensitivity may reduce the model's ability to make nuanced distinctions and affect its overall performance.\n",
    "\n",
    "If the predicted probability of a class in $A^{[2]}$ is lower than the actual label, we can say the model underestimates that class. In our example, the model predicted 0.7 for Class 3, but the actual label for this class is 1. Therefore, the model underestimated the probability of Class 3. $dW^{[2]}$ will also be low, indicating that we need to push the weights in the direction that reduces the cost.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Calibration**\n",
    "\"True probabilities\" refer to the actual frequencies of occurrence of each class within the dataset being modeled. Overestimating can indicate a lack of calibration in the model's predicted probabilities. A well-calibrated model should have predicted probabilities that closely reflect the true probabilities of the classes. A well-calibrated mode is one that provides predicted probabilities that align well with the true probabilities. For example, if the model assigns a predicted probability of $0.8$ to a certain class, it should mean that, on average, this class is expected to occur $80%$ of the time in reality.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Direction of Weight Adjustments**\n",
    "The positive values in $dW^{[2]}$ ($0.06$ and $0.12$ in our example) suggest that decreasing the corresponding weights would decrease the cost. The model's predictions for those classes were too low (underestimated) relative to the true labels. Conversely, the negative values in $dW^{[2]}$ ($-0.18$ in our example) suggest that increasing the corresponding weights would decrease the cost.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "---\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-07T06:39:44.998675Z",
     "start_time": "2023-06-07T06:39:44.995526Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
